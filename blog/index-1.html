<!DOCTYPE html>
<html prefix="" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Random exploring....">
<meta name="viewport" content="width=device-width">
<title>CODEBUG (old posts, page 1) | CODEBUG</title>
<link href="../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../assets/css/theme.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="../assets/css/screen.css">
<link rel="stylesheet" type="text/css" href="../assets/css/nav.css">
<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic%7COpen+Sans:700,400%7CInconsolata">
<link href="../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.xml">
<link rel="canonical" href="http://sijanb.com.np/blog/index-1.html">
<link rel="icon" href="../favicon.ico" sizes="16x16">
<link rel="prev" href="." type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]-->
</head>
<body class="nav-closed">

<div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
<li class="nav-opened" role="presentation">
            <a href=".">Blog</a>
        </li>
        <li class="nav-opened" role="presentation">
            <a href="../categories/">Tags</a>
        </li>
        <li class="nav-opened" role="presentation">
            <a href="../rss.xml">RSS feed</a>
        </li>
    
    
    </ul>
</div>
<span class="nav-cover"></span>

<div class="site-wrapper">
    <header class="main-header post-head no-cover"><nav class="main-nav overlay clearfix"><a class="blog-logo" href="http://sijanb.com.np/"><img src="../images/logo.png" alt="Blog Logo"></a>
            <a class="menu-button" href="#"><span class="burger">☰</span><span class="word">Menu</span></a>
        </nav><div class="vertical">
            <div class="main-header-content inner">
                <h1 class="page-title">CODEBUG (old posts, page 1)</h1>
                <h2 class="page-description">Random exploring....</h2>
            </div>
        </div>
        <a class="scroll-down icon-arrow-left" href="#content"><span class="hidden">Scroll Down</span></a>
    </header><main id="content" class="content" role="main"><div class="postindex">


<article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/implementation-of-perceptron-in-python/">implementation of perceptron in python</a></h2>
    </header><section class="post-excerpt"><div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1"># @Author: Sijan</span>
<span class="c1"># @Date:   2019-04-01</span>

<span class="kn">from</span> <span class="nn">random</span> <span class="k">import</span> <span class="n">randint</span>


<span class="k">def</span> <span class="nf">step_function</span><span class="p">(</span><span class="n">result</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Simple linear function which will be activated if the value is greater than 0.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">result</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="mi">0</span>


<span class="k">class</span> <span class="nc">Perceptron</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Perceptron class defines a neuron with attributes : weights, bias and learning rate.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_size</span><span class="p">)]</span>


<span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">node_input</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Implements product between input and weights</span>
<span class="sd">    """</span>
    <span class="n">node_sum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">node_sum</span> <span class="o">+=</span> <span class="n">perceptron</span><span class="o">.</span><span class="n">bias</span>

    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node_input</span><span class="p">):</span>
        <span class="c1"># print('input node is', item)</span>
        <span class="n">node_sum</span> <span class="o">+=</span> <span class="n">item</span> <span class="o">*</span> <span class="n">perceptron</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">step_function</span><span class="p">(</span><span class="n">node_sum</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">adjust_weight</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">node_input</span><span class="p">,</span> <span class="n">error</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Adjust weightage based on error. It simply scales input values towards right direction.</span>

<span class="sd">    """</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node_input</span><span class="p">):</span>
        <span class="n">perceptron</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">+=</span> <span class="n">item</span> <span class="o">*</span> <span class="n">error</span> <span class="o">*</span> <span class="n">perceptron</span><span class="o">.</span><span class="n">learning_rate</span>

    <span class="n">perceptron</span><span class="o">.</span><span class="n">bias</span> <span class="o">+=</span> <span class="n">error</span> <span class="o">*</span> <span class="n">perceptron</span><span class="o">.</span><span class="n">learning_rate</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Trains perceptron for given inputs.</span>
<span class="sd">    """</span>
    <span class="k">for</span> <span class="n">training_input</span><span class="p">,</span> <span class="n">training_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">actual_output</span> <span class="o">=</span> <span class="n">feedforward</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">training_input</span><span class="p">)</span>
        <span class="n">desired_output</span> <span class="o">=</span> <span class="n">training_output</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">desired_output</span> <span class="o">-</span> <span class="n">actual_output</span>
        <span class="n">adjust_weight</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">training_input</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'weight after adjustment'</span><span class="p">,</span> <span class="n">perceptron</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'bias after adjustment'</span><span class="p">,</span> <span class="n">perceptron</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">test_input</span><span class="p">,</span> <span class="n">test_output</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Predicts new inputs.</span>
<span class="sd">    """</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">feedforward</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">test_input</span><span class="p">)</span>

    <span class="c1"># if test_input[1] == test_output:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'input :</span><span class="si">%s</span><span class="s1"> gives output :</span><span class="si">%s</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'input :</span><span class="si">%s</span><span class="s1"> has true output :</span><span class="si">%s</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">test_output</span><span class="p">))</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>

    <span class="n">train_inputs</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
    <span class="n">train_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

    <span class="c1"># train perceptron</span>
    <span class="n">perceptron</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">train</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">train_inputs</span><span class="p">,</span> <span class="n">train_outputs</span><span class="p">)</span>

    <span class="c1"># test perceptron</span>
    <span class="n">test_input</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_output</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'...................................'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'...................................'</span><span class="p">)</span>
    <span class="n">predict</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">test_input</span><span class="p">,</span> <span class="n">test_output</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>weight after adjustment [0.0, 0.0]
bias after adjustment 0.0
weight after adjustment [0.0, 0.0]
bias after adjustment 0.0
weight after adjustment [0.0, 0.0]
bias after adjustment 0.0
weight after adjustment [0.5, 0.5]
bias after adjustment 0.5
weight after adjustment [0.5, 0.5]
bias after adjustment 0.0
weight after adjustment [0.5, 0.0]
bias after adjustment -0.5
weight after adjustment [0.5, 0.0]
bias after adjustment -0.5
weight after adjustment [1.0, 0.5]
bias after adjustment 0.0
weight after adjustment [1.0, 0.5]
bias after adjustment 0.0
weight after adjustment [1.0, 0.0]
bias after adjustment -0.5
weight after adjustment [0.5, 0.0]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -0.5
weight after adjustment [1.0, 0.5]
bias after adjustment -0.5
weight after adjustment [1.0, 0.5]
bias after adjustment -0.5
weight after adjustment [0.5, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 1.0]
bias after adjustment -0.5
weight after adjustment [1.0, 1.0]
bias after adjustment -0.5
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
weight after adjustment [1.0, 0.5]
bias after adjustment -1.0
...................................
...................................
input :(1, 1) gives output :1
input :(1, 1) has true output :1
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on

        <time class="post-date" datetime="2019-04-01T16:07:46+05:45">
            2019-04-01 16:07
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/understanding-probability/">Understanding Probability</a></h2>
    </header><section class="post-excerpt"><div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Randomness is not a property of a phenomenon. It is simply an unpredectability of occurence of events around you.  It occurs in different scenarios of our life. For example, while roaming around street, you found a coin; now you would certainly look for other coin around that spot. But, there will be not any certainty or possibility or pattern of finding one. Other examples are - tossing coin / dice, fluctuating market prices for common goods.</p>
<p>In the field of Mathematics and probability, we assign some numerical value for identifying each of this random outcome. i.e. we use probability to quantify randomness. And, probability of certain event is calculated by the relative frequency of that event in the experiment.</p>
<p>In probability, the current occurrence / selection you do for your experiment is an event. For example,fliping a coin is an event.And, the act of tossing the coin is called independent trail. If you do number of trails, it is called an experiment. And, all the possible outcomes of an experiment is called sample space. So, we can say that an event is also a subset of sample space.</p>
<p>Another example : Suppose you need to choose a point from an interval (10, 100). Your selection E = (12, 34) is an event.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p class="more"><a href="../posts/understanding-probability/">Read more…</a></p>
</div>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on

        <time class="post-date" datetime="2018-11-04T21:23:45+05:45">
            2018-11-04 21:23
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/using-perceptron-model-for-classification-an-illustrative-approach/">Using perceptron model for classification : an illustrative approach</a></h2>
    </header><section class="post-excerpt"><div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this post, we are going to devise a measurement tool (perceptron model) in order to classify : whether a person is infected by a diseases or not.</p>
<p>In binary terms, the output will be</p>

<pre><code>       {
            1   if infected 
            0   not infected
        } 

</code></pre>
<p>To build inputs for our neural network, we take readings from the patients and we will treat readings as follows :</p>

<pre><code>  body temperature = {
                          1   if body temperator &gt; 99'F
                         -1   if body temperator = 99'F
                     }

  heart rate = {
                      1   if heart rate &gt; 60 to 100
                     -1   if heart rate = 60 to 100
                 }

   blood pressure = {
                          1   if heart rate &gt; 120/80
                         -1   if heart rate = 120/80
                     }

</code></pre>
<p>So, input from each patient will be represented as a three dimensional vector:</p>

<pre><code>  input = (body temperatur, heart rate, blood pressure)
</code></pre>
<p>So, a person can now be represented as :</p>

<pre><code>(1, -1, 1)
i.e (body temperator &gt; 99'F, heart rate = 60 to 100, heart rate &gt; 120/80)</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let us create two inputs with desired output value</p>

<pre><code>      x1 = (1, 1, 1), d1 = 1 (infected)
       x2 = (-1, -1, -1), d2 = 0 (not infected)
</code></pre>
<p>Let us take initial values for weights and biases:
          weights, w0 = (-1, 0.5, 0)
          bias, b0 = 0.5</p>
<p>And, activation function:</p>

<pre><code>         A(S)   = {
                    1 if S &gt;=0
                    0 otherwise
                  }
</code></pre>
<h5 id="STEP-1">STEP 1<a class="anchor-link" href="../posts/using-perceptron-model-for-classification-an-illustrative-approach/#STEP-1">¶</a>
</h5>
<p>Feed <code>x1 = (1, 1, 1)</code> into the network.</p>
<p>weighted_sum:</p>

<pre><code>S = (-1, 0.5, 0) * (1, 1, 1)^T + 0
  = -1 + 0.5 + 0 + 0
  = -0.5

</code></pre>
<p>When passed through activation function A(-0.5) = 0 = y1
We passed an <code>infected</code> input vector, but our perceptron classified it as <code>not infected</code>.
Let's calculate the error term:</p>

<pre><code>             e = d1 - y1 = 1 - 0 = 1
</code></pre>
<p>Update weight as:</p>

<pre><code>             w1 = w0 + e * x1 = (-1, 0.5, 0) + 1 * (1, 1, 1) = (0, 1.5, 1)
</code></pre>
<p>And, update bias as:</p>

<pre><code>             b1 = b0 + e = 1</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="STEP-2">STEP 2<a class="anchor-link" href="../posts/using-perceptron-model-for-classification-an-illustrative-approach/#STEP-2">¶</a>
</h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, we feed second input <code>(-1, -1, -1)</code> into our network.</p>
<p>weighted_sum :</p>

<pre><code>S = w1 * x2^T + b1 
  = (0, 1.5, 1) * (-1, -1, -1)^T + 1
  = -1.5 - 1 + 1
  = -1.5
</code></pre>
<p>When passed through activation function A(-1.5) = 0 = y2
 We passed an <code>not infected</code> input vector, and our perceptron successfully classified it as <code>not infected</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="STEP-3">STEP 3<a class="anchor-link" href="../posts/using-perceptron-model-for-classification-an-illustrative-approach/#STEP-3">¶</a>
</h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since, our first input is mis-classified, so we will go for it.</p>
<p>weighted_sum :</p>

<pre><code>S = w1 * x1^T + b1 
  = (0, 1.5, 1) * (1, 1, 1)^T + 1
  = 1.5 + 1 + 1
  = 3.5
</code></pre>
<p>When passed through activation function A(3.5) = 1 = y3
 We passed an <code>infected</code> input vector, and our perceptron successfully classified it as <code>infected</code>.</p>
<p>Here, both input vectors are correctly classified. i.e algorithm is converged to a solution point.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on
                <a href="../categories/perceptron/">#perceptron</a>,

        <time class="post-date" datetime="2018-10-24T02:27:54+05:45">
            2018-10-24 02:27
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/what-is-perceptron-and-how-it-works/">What is perceptron and how it works?</a></h2>
    </header><section class="post-excerpt"><div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Perceptron is simply an artificial neuron capable of solving linear classification problems. It is made up of single layer feed-forward neural network.</p>
<p>A percentron can only takes binary input values and signals binary output for decision making.
The output decision (either0 or 1), is based on the value of weighted sum of inputs and weights.</p>
<p>Mathematically perceptron can be defined as :</p>
<p>output O(n)=<br>
                                {
     0   if   ∑wixi + $\theta$ &lt;= 0 <br>
                                                  1   if   ∑wixi + $\theta$ &gt; 0
             <br>
                                          } <br></p>
<p>$\theta$ = threshold / bias</p>
<p><img src="../images/perceptron.png"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p class="more"><a href="../posts/what-is-perceptron-and-how-it-works/">Read more…</a></p>
</div>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on
                <a href="../categories/perceptron/">#perceptron</a>,

        <time class="post-date" datetime="2018-10-24T02:21:47+05:45">
            2018-10-24 02:21
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/what-is-deep-learning-and-neural-network/">What is Deep Learning and Neural Network?</a></h2>
    </header><section class="post-excerpt"><div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Deep learning, in simpler version is a learning mechanisms for Neural networks. And, Neural networks are computational model mimicing human nervous system which are capable of learning. Like interconnected neurons in human brains, the neural network is also connected by different nodes. It receives signals as a set of inputs, perform calcuations and signals output based on some activation value.</p>
<p><img src="../images/artificial_neuron.png"></p>
<p>Here are some list of problems, that deep learning can solve</p>
<ol>
<li>Classification : object and speech recongnistion, classify sentiments from text</li>
<li>Clustering : Fraud detection </li>
</ol>
<p class="more"><a href="../posts/what-is-deep-learning-and-neural-network/">Read more…</a></p>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on
                <a href="../categories/deep-learning/">#deep learning</a>,
                <a href="../categories/neural-network/">#neural network</a>,

        <time class="post-date" datetime="2018-10-24T02:05:00+05:45">
            2018-10-24 02:05
        </time></footer></article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="." rel="prev">Newer posts</a>
            </li>
        </ul></nav><script>var disqus_shortname="blog-sijanb-com-np";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script></main><footer class="site-footer clearfix"><section class="poweredby">Contents © 2019         <a href="mailto:sijanonly@gmail.com">Sijan Bhandari</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         </section></footer>
</div>

    <script type="text/javascript" src="../assets/js/jquery.js"></script><script type="text/javascript" src="../assets/js/jquery.fitvids.js"></script><script type="text/javascript" src="../assets/js/index.js"></script>
</body>
</html>
