<!DOCTYPE html>
<html prefix="" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Data Exploration...">
<meta name="viewport" content="width=device-width">
<title>CODEBUG (page 6) | CODEBUG</title>
<link href="../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../assets/css/theme.css" rel="stylesheet" type="text/css">
<link href="../assets/css/custom.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="../assets/css/screen.css">
<link rel="stylesheet" type="text/css" href="../assets/css/nav.css">
<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400|Inconsolata">
<link href="../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.xml">
<link rel="canonical" href="https://sijanb.com.np/blog/">
<link rel="icon" href="../favicon.ico" sizes="16x16">
<link rel="next" href="index-5.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><!-- Font Awesome --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous">
</head>
<body class="nav-closed">

<div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
<li class="nav-opened nav-current" role="presentation">
            <a href=".">Blog</a>
        </li>
        <li class="nav-opened" role="presentation">
            <a href="../categories/">Tags</a>
        </li>
        <li class="nav-opened" role="presentation">
            <a href="../rss.xml">RSS feed</a>
        </li>
    
    
    </ul>
</div>
<span class="nav-cover"></span>

<div class="site-wrapper">
    <header class="main-header post-head no-cover"><nav class="main-nav overlay clearfix"><a class="blog-logo" href="https://sijanb.com.np/"><img src="../images/logo.png" alt="Blog Logo"></a>
            <a class="menu-button" href="#"><span class="burger">☰</span><span class="word">Menu</span></a>
        </nav><div class="vertical">
            <div class="main-header-content inner">
                <h1 class="page-title">CODEBUG (page 6)</h1>
                <h2 class="page-description">Data Exploration...</h2>
            </div>
        </div>
        <a class="scroll-down icon-arrow-left" href="#content"><span class="hidden">Scroll Down</span></a>
    </header><main id="content" class="content" role="main"><div class="postindex">


<article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/">Unlocking AI's Mind: Can Foundation Models Truly Understand Language?</a></h2>
    </header><section class="post-excerpt"><div class="cell border-box-sizing text_cell rendered" id="cell-id=67f352ff">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Unlocking-AI's-Mind:-Can-Foundation-Models-Truly-Understand-Language?">
<strong>Unlocking AI's Mind: Can Foundation Models Truly Understand Language?</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Unlocking-AI's-Mind:-Can-Foundation-Models-Truly-Understand-Language?">¶</a>
</h2>
<p>Have you ever found yourself chatting with an AI, maybe a chatbot or a language model, and been absolutely blown away by its fluency? It's pretty incredible, right? These systems can churn out text that sounds so natural, so human-like, that you might start to wonder: does it actually <em>get</em> what it's saying? Or is it just a super-sophisticated mimic, a kind of digital "parrot" that's really good at predicting the next word? This is a question that's not just for philosophers anymore; it's a crucial inquiry that could tell us so much about the true capabilities of foundation models and their potential to contribute to genuinely intelligent systems.</p>
<p>In this deep dive, we're going to tackle this fascinating conundrum head-on, focusing specifically on natural language. Why language? Well, it's a hallmark of human intelligence, isn't it? It’s central to how we think, communicate, and experience the world. The journey promises to be thought-provoking, as we explore what "understanding" really means in the context of AI, how these powerful models are trained, and what the implications are for their future development. So, buckle up, because we're about to explore the very essence of AI comprehension!</p>
<h3 id="The-Enigma-of-Understanding:-What-Are-We-Really-Asking?">
<strong>The Enigma of Understanding: What Are We Really Asking?</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#The-Enigma-of-Understanding:-What-Are-We-Really-Asking?">¶</a>
</h3>
<p>So, we're talking about "understanding" when it comes to AI, specifically foundation models. But what does that even mean? It's not a simple question, and honestly, it's one of the deepest philosophical puzzles lurking beneath the surface of all this exciting AI development. On one hand, you see models generating remarkably coherent and contextually appropriate language, leading you to believe there's some grasp of meaning. On the other, they sometimes slip into bizarre, nonsensical tangents, leaving you scratching your head and wondering if they're just glorified "stochastic parrots" – brilliant at predicting sequences but lacking true comprehension.</p>
<p>Our goal here isn't to give you a definitive "yes" or "no" answer (because, let's be real, it's complicated!). Instead, it's to clarify these questions, to give us a framework for discussing them intelligently, and to help structure the ongoing debates. We'll start by making sure we all have a good handle on what a "foundation model" truly is, especially focusing on their training, as that largely dictates what kind of information they receive about the world. Then, we'll talk about <em>why</em> it's so important to get clarity on these questions for the future of AI. And finally, we'll grapple with "understanding" itself – both what it means in principle (that's the metaphysics) and how we might actually, reliably determine if a model has achieved it (that's the epistemology). Ultimately, I think you'll find that being skeptical about future models' capacity for understanding might just be a bit premature. It's an open question, and that's an exciting place to be!</p>
<h4 id="Stochastic-Parrots-or-Budding-Intellects?-The-Current-State-of-AI-Fluency">
<strong>Stochastic Parrots or Budding Intellects? The Current State of AI Fluency</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Stochastic-Parrots-or-Budding-Intellects?-The-Current-State-of-AI-Fluency">¶</a>
</h4>
<p>Let's be honest, the best foundation models we have today are incredibly impressive. They can consume vast amounts of language and then produce their own, often with a fluency that's almost eerie. You read what they write, and it just <em>sounds</em> right, doesn't it? They can summarize complex texts, write creative stories, and even hold surprisingly coherent conversations. It’s a bit like watching a master illusionist – you know there’s a trick, but you can’t quite figure it out.</p>
<p>However, despite this striking fluency, these models invariably lapse into moments of utter incoherence, almost as if the illusion breaks. They might contradict themselves, make factual errors, or generate responses that are perfectly grammatical but completely nonsensical in context. It's these "lapses" that lead many, including some prominent researchers, to describe them as mere "stochastic parrots" – highly sophisticated pattern-matchers that simply regurgitate combinations of words they've seen, without any underlying comprehension. The big question, then, is this: are these lapses definitive proof of inherent limitations, suggesting that true understanding is forever beyond their grasp? Or are they simply growing pains, temporary hiccups in the evolution towards a more profound form of AI intelligence? This is the core of our inquiry, and it demands a closer look at how these models actually work.</p>
<h4 id="Defining-Our-Terms:-What-Constitutes-a-Foundation-Model?">
<strong>Defining Our Terms: What Constitutes a Foundation Model?</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Defining-Our-Terms:-What-Constitutes-a-Foundation-Model?">¶</a>
</h4>
<p>Before we dive deeper into the mysteries of AI understanding, let's make sure we're all on the same page about what a "foundation model" actually is. You see, there isn't one super-strict technical definition. Instead, it's more like a family name for a large and ever-evolving group of AI models. This fluid definition can make it a bit tricky to pin down their fundamental properties and limitations, as the family portrait keeps getting new members!</p>
<p>However, there's arguably one defining characteristic that unites all foundation models: they are <em>self-supervised</em>. And for our discussion, we're going to zero in on cases where self-supervision is the <em>only</em> formal objective guiding the model's learning. So, what does that mean in practice? Let's break it down.</p>
<h5 id="The-Self-Supervision-Engine:-Learning-from-Co-occurrence-Patterns">
<strong>The Self-Supervision Engine: Learning from Co-occurrence Patterns</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#The-Self-Supervision-Engine:-Learning-from-Co-occurrence-Patterns">¶</a>
</h5>
<p>So, what's the secret sauce that makes a foundation model, well, a foundation model? It really boils down to one defining characteristic: self-supervision. This isn't just a fancy technical term; it's the core engine driving their learning process. Imagine this: the model's sole objective is to learn abstract co-occurrence patterns in the sequences of symbols it was trained on. It's like being given a massive, scrambled jigsaw puzzle where your only goal is to figure out which pieces tend to sit next to each other, without ever seeing the final picture.</p>
<p>This seemingly simple task is incredibly powerful. It enables many of these models to generate remarkably plausible strings of symbols. For example, you might prompt a model with "The sandwich contains peanut" and ask it to generate a continuation – and voilà, it might complete it with "butter and jelly." Or, if it's structured for gap-filling, you could give it "The sandwich contains __ and jelly" and it would likely fill in "peanut butter." Both of these impressive feats derive directly from the model's ability to extract these intricate co-occurrence patterns from its vast training data. Crucially, on the face of it, this kind of self-supervision doesn't directly tell the model anything about what the symbols <em>mean</em>. It's purely about statistical relationships between words.</p>
<h5 id="Beyond-Text:-The-Power-of-Multimodal-Training-Data">
<strong>Beyond Text: The Power of Multimodal Training Data</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Beyond-Text:-The-Power-of-Multimodal-Training-Data">¶</a>
</h5>
<p>Now, you might be thinking, "If it's just about words co-occurring, how can it ever really understand the <em>world</em>?" And that's a brilliant question, because on the surface, knowing that "peanut" often follows "sandwich contains" doesn't tell a model anything about what a sandwich actually <em>is</em>, or what jelly tastes like, or how these objects are physically combined. This might seem to suggest an inherent, unshakeable limitation on what a foundation model could truly achieve in terms of understanding. It’s like trying to learn about an elephant by only reading a dictionary definition – you get the words, but not the experience.</p>
<p>However, here's where things get interesting: we don't have to limit the model to seeing <em>only</em> textual input. Imagine a foundation model trained on a much wider array of "symbols" – not just human language, but also computer code, vast database files, millions of images, audio recordings, and even sensor readings from the real world. As long as its primary objective is still to learn co-occurrence patterns within these diverse sequences, it still qualifies as a foundation model by our definition. In this richer learning environment, the model might start to represent powerful associations between, say, a piece of text describing a "dog" and actual pixel values of dogs in images, or between a spoken word and a sensor reading from a particular object. These cross-modal associations could potentially reflect crucial aspects of the world we inhabit and the language we use to describe it, adding a whole new dimension to its "understanding" of connections.</p>
<h3 id="Why-Does-Understanding-Matter?-The-Stakes-of-AI-Comprehension">
<strong>Why Does Understanding Matter? The Stakes of AI Comprehension</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Why-Does-Understanding-Matter?-The-Stakes-of-AI-Comprehension">¶</a>
</h3>
<p>Okay, so we're grappling with this huge question of whether foundation models can truly understand. But why should <em>we</em> care? Why is this question so important for the future of AI? It's not just an academic debate; it has real-world implications, especially as these incredibly powerful models get deployed for all sorts of purposes, with various functionalities. Some of our most critical goals in deploying these AI systems might only be met if the model is genuinely capable of understanding. Let me walk you through a few key reasons why this matters so much.</p>
<h4 id="The-Cornerstone-of-Trust:-Can-We-Rely-on-Language-We-Don't-Understand?">
<strong>The Cornerstone of Trust: Can We Rely on Language We Don't Understand?</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#The-Cornerstone-of-Trust:-Can-We-Rely-on-Language-We-Don't-Understand?">¶</a>
</h4>
<p>Let's talk about trust. When you interact with another human, a certain level of trust is built on the assumption that they understand what you're saying and what they're saying back. But what about an AI? Can you truly trust a system's linguistic behavior if you're not convinced it understands the language it's using? Sure, we trust engineered systems to do things like manufacture auto parts without questioning their "understanding." But language might be different, precisely because it's so uniquely human. Language is also a tool for deception and misrepresentation, so simply understanding doesn't guarantee trust.</p>
<p>However, many would argue that understanding could be a <em>necessary condition</em> for trust in the context of language use. If an AI system is going to be communicating with us, making recommendations, or even delivering critical information, we need to feel confident that it grasps the nuances, implications, and potential consequences of its words. Without that underlying comprehension, its fluent output could feel hollow, unreliable, and ultimately, untrustworthy. The mere possibility that understanding is indispensable for trust provides a strong motivation to build a robust framework for theorizing about it. It's like entrusting your valuable possessions to someone who speaks your language but seems to miss the underlying meaning of your instructions – you’d be pretty nervous, wouldn't you?</p>
<h4 id="Peering-Inside-the-Black-Box:-Understanding-for-Interpretability">
<strong>Peering Inside the Black Box: Understanding for Interpretability</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Peering-Inside-the-Black-Box:-Understanding-for-Interpretability">¶</a>
</h4>
<p>Imagine you're trying to figure out why an AI made a certain decision or generated a particular piece of text. If that AI truly "understood" the language, it might mean it has an internal model of the world that it's constantly updating – kind of like how our own brains work when we're processing information and adapting to new situations. If we, as the engineers and designers, could analyze how the linguistic inputs and outputs of the AI interface with this internal model, oh, the insights we could gain!</p>
<p>This ability to "peer inside the black box" could lead to substantial gains in interpretability. We could better predict how the system will behave in different scenarios, and crucially, we could gain more control over its actions. It's like having the blueprints to a complex machine versus just knowing how to press its "on" button. Understanding could unlock a deeper level of insight into the AI's reasoning, allowing us to debug, refine, and steer it more effectively. This isn't just about curiosity; it's about building more reliable and controllable AI systems that we can truly work with, rather than just react to.</p>
<h4 id="The-Weight-of-Words:-Understanding-and-Accountability-in-AI">
<strong>The Weight of Words: Understanding and Accountability in AI</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#The-Weight-of-Words:-Understanding-and-Accountability-in-AI">¶</a>
</h4>
<p>This point ties in closely with trust and interpretability, but it adds another layer: accountability. As AI agents become more sophisticated and more integrated into our lives, especially in roles where they produce language, we might eventually want to hold them accountable for what they say or do. Think about an AI giving medical advice, or an AI assisting in legal proceedings. If that AI generates harmful or incorrect information, who is responsible? How do we attribute blame or responsibility?</p>
<p>Depending on how we define concepts like accountability, responsibility, and agency, genuine language understanding might emerge as a prerequisite. It's a complex philosophical tangle, for sure, but the underlying intuition is powerful: if an entity truly <em>understands</em> the implications of its words, then it feels more reasonable to hold it to some standard of accountability. The potential for AI to be deployed in sensitive contexts makes this question of understanding and accountability not just theoretical, but deeply practical and ethically urgent. The mere possibility that understanding will play an indispensable role in any of these matters provides strong motivation to develop a framework for theorizing about it.</p>
<h3 id="Unraveling-Understanding:-Metaphysics-vs.-Epistemology">
<strong>Unraveling Understanding: Metaphysics vs. Epistemology</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Unraveling-Understanding:-Metaphysics-vs.-Epistemology">¶</a>
</h3>
<p>Alright, let's get a little philosophical, but in a super practical way. When we ask if a foundation model can "understand," we're actually asking two distinct, but related, questions. It's like trying to figure out if you've reached a destination: first, you need to know what the destination <em>is</em> (the metaphysics), and then you need to figure out how you'll <em>know</em> when you've arrived (the epistemology). Conflating these two can lead to a lot of confusion in debates about AI.</p>
<p>Metaphysics, in this context, concerns what it would mean, in principle, for an agent to achieve understanding. It's about the ultimate target, the "nature" of understanding itself. Epistemology, on the other hand, is about how, in practice, we could ever reliably determine that an agent <em>has</em> achieved that relevant type of understanding. So, our strategy for figuring out <em>if</em> a model understands (epistemology) is going to depend quite a bit on what we think understanding <em>is</em> in the first place (metaphysics). It’s crucial to separate these two threads to make progress in this complex discussion.</p>
<h4 id="The-Metaphysics-of-Understanding:-What-Is-It,-In-Principle?">
<strong>The Metaphysics of Understanding: What Is It, In Principle?</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#The-Metaphysics-of-Understanding:-What-Is-It,-In-Principle?">¶</a>
</h4>
<p>So, let's start with the "what." What does it mean, in principle, for <em>any</em> agent – human or AI – to truly understand natural language? Philosophy gives us a few big ideas, and it's helpful to see how they connect to the world of AI and natural language processing (NLP). While this is a simplified view of a very rich philosophical landscape, these three broad classes of views are particularly relevant to our discussion.</p>
<h5 id="Internalism:-The-Mind's-Eye-of-Language">
<strong>Internalism: The Mind's Eye of Language</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Internalism:-The-Mind's-Eye-of-Language">¶</a>
</h5>
<p>Imagine understanding language as a process that happens entirely inside your head. That's the core idea of internalism. It suggests that when we understand, we're essentially retrieving or constructing the right "internal representational structures" in response to the words we hear or read. So, to understand a word like "tree," your brain might activate a complex network of internal concepts, images, and associations related to trees – their shape, their leaves, the feeling of bark, etc. For an AI, this would mean having a rich, internal conceptual repertoire that can be meaningfully linked to linguistic input.</p>
<p>If internalism is correct, then language understanding isn't even possible without this kind of rich internal "mental" life. This view strongly suggests that if an AI truly understands, we should, in principle, be able to analyze its internal structure and see how it processes and represents information. It opens the door to a robust kind of "interpretability," where we might be able to trace how linguistic input influences the AI's internal model of the world.</p>
<h5 id="Referentialism:-Grounding-Language-in-the-World">
<strong>Referentialism: Grounding Language in the World</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Referentialism:-Grounding-Language-in-the-World">¶</a>
</h5>
<p>Now, let's shift gears. What if understanding isn't just about what's inside your head, but also about how language connects to the real world? That's where referentialism comes in. Roughly speaking, this view suggests that an agent understands language when they know what it would take for different sentences in that language to be true, relative to a specific context. It's all about "reference." Words have referents – they point to things in the world. And declarative statements can be evaluated for their truth.</p>
<p>So, for a referentialist, understanding "The cat is on the mat" means you can recognize a situation where that sentence is true, and one where it's false. For an AI, this would imply a capacity to evaluate utterances in relation to presented situations or scenarios. If a model only receives linguistic input, its capacity to learn this kind of mapping might be fundamentally limited. However, if it's exposed to diverse digital traces of the world – images, audio, sensor readings – then the co-occurrence patterns between language and these real-world signals could provide enough information for the model to induce high-fidelity proxies for this required mapping. This is where multimodal training becomes incredibly important.</p>
<h5 id="Pragmatism:-Understanding-as-Right-Use-of-Language">
<strong>Pragmatism: Understanding as Right Use of Language</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Pragmatism:-Understanding-as-Right-Use-of-Language">¶</a>
</h5>
<p>Finally, we have pragmatism, which takes a different approach. This view suggests that understanding doesn't necessarily require complex internal representations or even a direct connection to "truth" or "reference" in the world. Instead, what truly matters is how an agent <em>uses</em> language. If you can use language correctly – if you make appropriate conversational moves, engage in logical inferences, and behave in ways that demonstrate a command of the language – then you understand it. The relevant verbal abilities <em>constitute</em> understanding.</p>
<p>This perspective is famously linked to the Turing Test, where the focus is purely on behavioral performance. If an AI can convincingly "pretend" to be human in a conversation, then for a pragmatist, it understands. The beauty of this view is its simplicity in terms of testing: just observe behavior. However, its potential drawback is that achieving language understanding on this view doesn't imply anything about our ability to trust or interpret the system, as it guarantees nothing about the agent's internal structure or its relationship to the non-linguistic world. The philosophical view we adopt has a huge impact on how we frame the question of whether a foundation model could <em>in principle</em> understand language.</p>
<h4 id="The-Epistemology-of-Understanding:-How-Can-We-Know-for-Sure?">
<strong>The Epistemology of Understanding: How Can We Know for Sure?</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#The-Epistemology-of-Understanding:-How-Can-We-Know-for-Sure?">¶</a>
</h4>
<p>Okay, so we've explored what understanding <em>could</em> be, metaphysically speaking. Now comes the really tricky part: how do we actually <em>know</em> if an AI has achieved it? This is the epistemology of understanding – the practical challenge of reliably determining whether a model has truly comprehended language. If our metaphysics of understanding (what it <em>is</em>) is internalist or referentialist, then behavioral tests alone will always be, at best, imperfect. Why? Because they might have gaps that allow unsophisticated models to slip through, or a truly understanding system might exist that we simply can't prove through behavior alone.</p>
<h5 id="The-Elusive-Test:-Why-Benchmarks-Fall-Short">
<strong>The Elusive Test: Why Benchmarks Fall Short</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#The-Elusive-Test:-Why-Benchmarks-Fall-Short">¶</a>
</h5>
<p>Pragmatism, with its focus on observable behavior, seems to offer a straightforward path for testing understanding. Just see if the AI acts like it understands, right? However, history tells us this isn't as simple as it sounds. Take the famous Turing Test, for example. Numerous artificial agents have actually "passed" it, meaning they've fooled human judges into thinking they're human in a conversation. Yet, none of these systems have been widely accepted as genuinely "intelligent" as a result. Why? Because we intuitively feel there's something missing, something beyond mere conversational fluency.</p>
<p>Similarly, in recent years, AI researchers have proposed many benchmark tasks within Natural Language Processing (NLP) to evaluate specific aspects of understanding – like answering simple questions or performing commonsense reasoning. And guess what? When systems surpass human performance on these tests, the community's usual response isn't "Wow, it understands!" but rather, "Ah, the test was flawed; it didn't <em>really</em> capture understanding." It seems there's some elusive suite of behaviors that represents our true target, but we just can't seem to pin it down into a practical, definitive test. This constant moving of the goalposts might actually reveal that, deep down, what we <em>really</em> have in mind for understanding is more akin to internalism or referentialism – something that goes beyond just observable behavior.</p>
<h5 id="Probing-the-Depths:-Structural-Evaluation-Methods">
<strong>Probing the Depths: Structural Evaluation Methods</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Probing-the-Depths:-Structural-Evaluation-Methods">¶</a>
</h5>
<p>If we believe that true understanding involves something more than just outward behavior – if we lean towards internalism or referentialism as our "gold standard" – then behavioral tests, while useful, will always be imperfect. They're like trying to understand a complex machine just by pushing its buttons; you might see what it <em>does</em>, but not necessarily <em>how</em> it does it or <em>why</em>. There are two key imperfections here: first, behavioral tests will inevitably have gaps that simpler models could exploit, giving a false sense of understanding. Second, a system might genuinely have achieved the internal mappings required by internalism or referentialism, but our behavioral tests might simply be inadequate to reveal this. Think about GPT-3: depending on how you "prompt" it, you can get incredibly coherent outputs or absolute nonsense, highlighting how challenging it is to elicit its full capabilities.</p>
<p>Therefore, both internalism and referentialism really call for <em>structural evaluation methods</em>. These are techniques that allow us to study the AI's <em>internal representations</em>, probing them for information, analyzing their internal dynamics, and perhaps even actively manipulating them in controlled experiments to understand cause and effect. While there might be fundamental limitations to how much we can truly understand the "inner workings" of a truly complex foundation model, it's clear that these methods will be invaluable if our ultimate target for understanding aligns with internalist or referentialist views. We need to go beyond just what the AI <em>says</em> and try to figure out what it <em>knows</em> and how it <em>thinks</em>.</p>
<h3 id="Charting-the-Course-Forward:-The-Path-to-AI-Understanding">
<strong>Charting the Course Forward: The Path to AI Understanding</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Charting-the-Course-Forward:-The-Path-to-AI-Understanding">¶</a>
</h3>
<p>So, after all this discussion, where does that leave us? It's abundantly clear that there are no easy, cut-and-dried answers to the monumental question of whether foundation models will ever truly understand language. It's a deep, multi-layered puzzle that touches on philosophy, computer science, and even our own definition of intelligence. To even begin to address this question meaningfully, one must first wrestle with difficult metaphysical questions about what understanding fundamentally <em>is</em>, and then tackle the equally challenging epistemological question of how we could ever reliably know if a model has achieved it.</p>
<h4 id="The-Multimodal-Advantage:-A-Promising-Avenue">
<strong>The Multimodal Advantage: A Promising Avenue</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#The-Multimodal-Advantage:-A-Promising-Avenue">¶</a>
</h4>
<p>So, if we're serious about pursuing language understanding in artificial agents through foundation models, what's our best bet? The discussion above strongly suggests one practical conclusion: multimodal training regimes may be the most viable strategy. Why? Because simply feeding a model text alone might fundamentally limit its ability to truly grasp the meaning of symbols in the way that internalism or referentialism demand. If a model only sees words, it learns correlations between words. It doesn't get direct information about what those words <em>mean</em> in the real world.</p>
<p>However, if a foundation model is exposed to a rich tapestry of diverse digital traces – images, audio, sensor readings, alongside language – then the co-occurrence patterns it learns could provide far more robust and nuanced information. It could learn strong associations between a textual description of a "cat" and actual images of cats, or between the sound of "rain" and sensor data indicating precipitation. These multimodal associations might just be enough to provide the model with the requisite information to induce high-fidelity proxies for connecting language to the world, thereby bringing it closer to a form of understanding that goes beyond mere "stochastic parroting." It's like teaching a child about a dog not just by saying the word, but by showing pictures, playing barks, and letting them feel its fur.</p>
<h4 id="The-Unanswered-Question:-Is-Self-Supervision-Enough?">
<strong>The Unanswered Question: Is Self-Supervision Enough?</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#The-Unanswered-Question:-Is-Self-Supervision-Enough?">¶</a>
</h4>
<p>So, if multimodal training is the promising path, that still leaves us with a monumental unanswered question: is self-supervision, even with all this rich, diverse data, <em>sufficient</em> for understanding? This remains an entirely open question, and honestly, we don't have a definitive answer yet. While a multimodal approach seems more likely to provide the necessary information, whether the <em>method</em> of simply learning co-occurrence patterns, no matter how complex or varied, can truly lead to genuine understanding is still a matter of debate.</p>
<p>We don't have definitive reasons to think that foundation models <em>cannot</em> achieve understanding. But neither is it obvious that they <em>alone</em> could ever achieve it without other mechanisms or perhaps even new paradigms of AI architecture and training. This means skepticism about the capacity of future models to understand natural language might be premature. The journey is far from over, and the possibilities are still wide open for exploration. It's a testament to the exciting, unknown frontiers of AI research that lie ahead.</p>
<h2 id="Conclusion:-The-Journey-Towards-Truly-Intelligent-AI">
<strong>Conclusion: The Journey Towards Truly Intelligent AI</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Conclusion:-The-Journey-Towards-Truly-Intelligent-AI">¶</a>
</h2>
<p>We've embarked on quite the intellectual journey, haven't we? From the current impressive, yet sometimes perplexing, fluency of foundation models, to the profound philosophical questions of what "understanding" truly entails, it's clear we're standing at a fascinating crossroads in the development of artificial intelligence. We've seen that understanding is a multi-faceted concept, encompassing internal representations, connections to the real world, and effective language use. And we've wrestled with the challenge of how we could ever definitively test for such understanding in an AI.</p>
<p>Ultimately, while current foundation models might sometimes feel like advanced mimics, we've found no definitive, a priori reason to rule out the possibility of future models achieving genuine language comprehension. The potential of multimodal training, allowing models to learn from a richer, more diverse set of data beyond just text, seems to be a particularly promising avenue. However, whether the self-supervised learning paradigm alone will be sufficient for this grand leap remains an open, compelling question. This isn't a dead-end; it's an exciting frontier for research, pushing the boundaries of what we thought possible for artificial intelligence. The quest for true AI understanding continues, and it promises to be one of the most intellectually stimulating endeavors of our time.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=5de8ac00">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Frequently-Asked-Questions-(FAQs)">
<strong>Frequently Asked Questions (FAQs)</strong><a class="anchor-link" href="../posts/unlocking-ais-mind-can-foundation-models-truly-understand-language/#Frequently-Asked-Questions-(FAQs)">¶</a>
</h3>
<p><strong>Q1: What's the main difference between a "stochastic parrot" and a truly understanding AI?</strong>
A1: A "stochastic parrot" is a term used to describe an AI that is excellent at generating fluent, human-like language by predicting the next most probable word based on patterns in its training data. It sounds coherent but lacks true comprehension or an internal model of meaning. A truly understanding AI, on the other hand, would not only be fluent but would also grasp the underlying meaning, context, and implications of the language it processes and generates, potentially by connecting it to real-world concepts or internal representations.</p>
<p><strong>Q2: Why is understanding important for AI, beyond just generating fluent text?</strong>
A2: Understanding is crucial for several reasons: it's seen as a necessary condition for trusting an AI's linguistic behavior, as true comprehension implies reliability and reduces the risk of unintended or nonsensical outputs. It also enhances the interpretability of AI systems, allowing developers to better understand <em>why</em> an AI produced certain language. Lastly, it could become a prerequisite for holding AI agents accountable for their linguistic actions in the future.</p>
<p><strong>Q3: What does "self-supervision" mean in the context of foundation models?</strong>
A3: Self-supervision means the model learns without explicit human-provided labels or annotations for every piece of data. Instead, it creates its own "supervision signal" from the data itself. For language models, this often means tasks like predicting missing words in a sentence or predicting the next word in a sequence. The model learns by identifying abstract co-occurrence patterns in the data it was trained on.</p>
<p><strong>Q4: How does multimodal training potentially help foundation models understand better?</strong>
A4: Multimodal training involves exposing foundation models to a wide range of data types beyond just text, such as images, audio, and sensor readings. By learning co-occurrence patterns across these different modalities (e.g., associating the word "dog" with pictures of dogs and sounds of barking), the model can potentially build richer, more grounded internal representations that connect language to real-world concepts, moving beyond purely statistical word associations.</p>
<p><strong>Q5: Is it possible for an AI to pass the Turing Test without truly understanding?</strong>
A5: According to philosophical views like pragmatism, passing the Turing Test, which focuses on observable linguistic behavior, would imply understanding. However, under other views like internalism or referentialism, it's widely believed that an AI could indeed pass the Turing Test (i.e., convincingly mimic human conversation) without possessing true underlying understanding, as its performance might stem from sophisticated pattern-matching rather than genuine comprehension of meaning or connection to the real world.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=59d5de87">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Citation: Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., ... &amp; Liang, P. (2022). On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258. Available at: <a href="https://arxiv.org/abs/2108.07258">https://arxiv.org/abs/2108.07258</a></p>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on
                <a href="../categories/large-language-models/">#large-language-models</a>,
                <a href="../categories/llms/">#llms</a>,
                <a href="../categories/transformers/">#transformers</a>,

        <time class="post-date" datetime="2025-07-27T19:11:05+05:45">
            2025-07-27
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/the-ai-revolution-how-foundation-models-are-reshaping-our-interactions/">The AI Revolution: How Foundation Models are Reshaping Our Interactions</a></h2>
    </header><section class="post-excerpt"><div class="cell border-box-sizing text_cell rendered" id="cell-id=bac28873">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-AI-Revolution:-How-Foundation-Models-are-Reshaping-Our-Interactions">
<strong>The AI Revolution: How Foundation Models are Reshaping Our Interactions</strong><a class="anchor-link" href="../posts/the-ai-revolution-how-foundation-models-are-reshaping-our-interactions/#The-AI-Revolution:-How-Foundation-Models-are-Reshaping-Our-Interactions">¶</a>
</h2>
<p>Have you ever wondered how artificial intelligence is evolving right before our very eyes? It's no secret that AI is changing the world, but the pace of innovation is truly breathtaking. We're talking about a fundamental shift in how we, as humans, interact with technology, and it's all thanks to something called "foundation models."</p>
<p>Think about it: remember when AI was mostly confined to highly specialized tasks, requiring tons of expertise to even get started? Well, those days are rapidly becoming a distant memory. Today, we're witnessing a paradigm shift, a movement towards AI that's more accessible, more versatile, and dare I say, more <em>human</em> in its interactions. This isn't just about making things a little bit easier; it's about unlocking entirely new possibilities for what we can achieve with AI, whether you're a seasoned developer or just someone curious about what the future holds. We're on the cusp of a truly interactive AI era, and I'm excited to walk you through how foundation models are at the heart of it all.</p>
<h3 id="Stepping-into-the-Future:-What-Exactly-are-Foundation-Models?">
<strong>Stepping into the Future: What Exactly are Foundation Models?</strong><a class="anchor-link" href="../posts/the-ai-revolution-how-foundation-models-are-reshaping-our-interactions/#Stepping-into-the-Future:-What-Exactly-are-Foundation-Models?">¶</a>
</h3>
<p>So, what's the big deal with these "foundation models" everyone's talking about? Well, think of them as the superheroes of the AI world – the ones with incredible versatility and power. You might have already encountered their early forms, like GPT-3, which can generate human-like text, or DALL·E, which conjures up amazing images from simple descriptions. These aren't just one-trick ponies; they're incredibly adaptable, able to handle a wide range of tasks and seamlessly integrate different forms of data, from plain text to stunning visuals.</p>
<img alt="No description has been provided for this image" src="../images/foundation_models_human_interaction2.png"><p class="more"><a href="../posts/the-ai-revolution-how-foundation-models-are-reshaping-our-interactions/">Read more…</a></p>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on
                <a href="../categories/large-language-models/">#large-language-models</a>,
                <a href="../categories/llms/">#llms</a>,
                <a href="../categories/transformers/">#transformers</a>,

        <time class="post-date" datetime="2025-07-25T23:22:53+05:45">
            2025-07-25
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/">How AI Foundation Models Are Revolutionizing Complex Reasoning: From Game-Playing to Mathematical Discovery</a></h2>
    </header><section class="post-excerpt"><div class="cell border-box-sizing text_cell rendered" id="cell-id=6f6ec36a">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Introduction:-The-Pursuit-of-Advanced-Artificial-Intelligence">Introduction: The Pursuit of Advanced Artificial Intelligence<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#Introduction:-The-Pursuit-of-Advanced-Artificial-Intelligence">¶</a>
</h3>
<p>Envision a computer capable of solving a geometry problem in a manner akin to a human—not merely by memorizing formulas, but by visualizing shapes, identifying patterns, and making innovative connections. Modern AI foundation models are beginning to achieve this, representing a transformative development in how machines tackle complex reasoning tasks.</p>
<p>The advancement of artificial intelligence has consistently been fueled by ambitious objectives: creating machines that can engage in strategic games, uncover mathematical theorems, and solve problems that demand genuine insight rather than mere computational power. Today's foundation models signify a considerable advancement in this endeavor, merging pattern recognition capabilities with adaptable problem-solving skills.</p>
<h3 id="The-Evolution-of-AI-Reasoning:-From-Symbol-Manipulation-to-Data-Driven-Learning">The Evolution of AI Reasoning: From Symbol Manipulation to Data-Driven Learning<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#The-Evolution-of-AI-Reasoning:-From-Symbol-Manipulation-to-Data-Driven-Learning">¶</a>
</h3>
<h4 id="The-Limitations-of-Symbolic-AI">The Limitations of Symbolic AI<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#The-Limitations-of-Symbolic-AI">¶</a>
</h4>
<p>Traditional AI systems predominantly relied on symbolic reasoning—programming computers with explicit rules and logical operations. This approach is akin to providing someone with a detailed cookbook for every conceivable cooking scenario. While effective for well-defined problems, it quickly became cumbersome when confronted with the complexities of real-world situations.</p>
<p>For instance, early chess programs utilized brute-force search methods combined with manually crafted evaluation functions. Programmers encoded knowledge about advantageous chess positions, resulting in systems that were inflexible and limited in adaptability.</p>
<h4 id="The-Shift-to-Data-Driven-Learning">The Shift to Data-Driven Learning<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#The-Shift-to-Data-Driven-Learning">¶</a>
</h4>
<p>Modern foundation models adopt a fundamentally different strategy. Rather than depending on pre-defined rules, these systems learn patterns from extensive datasets. This is comparable to the distinction between memorizing a phrasebook and genuinely learning a language—the latter is significantly more versatile and powerful.</p>
<p>Take AlphaGo as an example; it transformed the ancient game of Go by analyzing millions of games and even competing against itself, uncovering innovative strategies that astonished even expert players. This data-centric approach unlocked possibilities that traditional rule-based systems could not achieve.</p>
<h3 id="Addressing-Complex-Reasoning-Challenges">Addressing Complex Reasoning Challenges<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#Addressing-Complex-Reasoning-Challenges">¶</a>
</h3>
<h4 id="The-Geometry-Problem:-An-Insight-into-AI-Reasoning">The Geometry Problem: An Insight into AI Reasoning<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#The-Geometry-Problem:-An-Insight-into-AI-Reasoning">¶</a>
</h4>
<p>Let us explore a specific example that highlights the intricacies of reasoning tasks. Proving that the base angles of an isosceles triangle are equal may seem straightforward for a human but presents considerable challenges for AI systems.</p>
<p><strong>The Human Approach:</strong></p>
<ul>
<li>Visualize the triangle and its characteristics</li>
<li>Recognize the symmetry inherent in the isosceles shape</li>
<li>Make a creative leap by drawing an angle bisector from the apex</li>
<li>Utilize congruent triangles to finalize the proof</li>
</ul>
<p><strong>The AI Challenge:</strong>
At each stage, an AI system encounters numerous possibilities. It could draw various auxiliary lines, introduce different geometric constructions, or apply multiple theorems, resulting in an almost infinite search space, making it impractical to explore every option.</p>
<p>Foundation models excel in this regard. Instead of aimlessly navigating through all possibilities, they can learn to identify promising patterns and make informed decisions about which paths to pursue.</p>
<h4 id="The-Universal-Nature-of-Reasoning-Problems">The Universal Nature of Reasoning Problems<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#The-Universal-Nature-of-Reasoning-Problems">¶</a>
</h4>
<p>Interestingly, similar structures manifest across diverse domains. Consider the following parallels:</p>
<p><strong>Chemical Synthesis vs. Mathematical Proofs:</strong></p>
<ul>
<li>Both involve constructing tree-like structures</li>
<li>In chemistry: combining molecules to form compounds</li>
<li>In mathematics: connecting logical steps to derive conclusions</li>
<li>Both necessitate creative insights regarding which paths to follow</li>
</ul>
<p><strong>Software Development vs. Theorem Proving:</strong></p>
<ul>
<li>Both begin with high-level objectives and decompose them into specific tasks</li>
<li>Both require comprehension of abstract concepts and their tangible applications</li>
<li>Both benefit from recognizing reusable patterns and methodologies</li>
</ul>
<p>This universality implies that reasoning skills acquired in one domain can be applied to others, which is a significant advantage of foundation models.</p>
<h3 id="The-Three-Pillars-of-Foundation-Model-Reasoning">The Three Pillars of Foundation Model Reasoning<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#The-Three-Pillars-of-Foundation-Model-Reasoning">¶</a>
</h3>
<h4 id="1.-Generativity:-Crafting-Solutions-from-the-Ground-Up">1. Generativity: Crafting Solutions from the Ground Up<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#1.-Generativity:-Crafting-Solutions-from-the-Ground-Up">¶</a>
</h4>
<p>Traditional AI systems were confined to predicting from a limited set of options. In contrast, foundation models can generate entirely new solutions by modeling the probability distribution of successful approaches.</p>
<p><strong>Analogy:</strong> This can be likened to the difference between answering multiple-choice questions and writing an essay. Multiple-choice questions restrict you to predefined options, while essay writing enables creative expression and original ideas. Foundation models function more like the essay approach, capable of generating unique constructions, innovative program code, or creative mathematical conjectures.</p>
<p><strong>Real-World Applications:</strong></p>
<ul>
<li>
<strong>Drug Discovery:</strong> Generating new molecular structures with desired characteristics</li>
<li>
<strong>Software Engineering:</strong> Developing novel algorithms to address specific challenges</li>
<li>
<strong>Mathematical Research:</strong> Proposing new theorems and proof strategies</li>
</ul>
<h4 id="2.-Universality:-Cross-Domain-Learning">2. Universality: Cross-Domain Learning<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#2.-Universality:-Cross-Domain-Learning">¶</a>
</h4>
<p>A key strength of foundation models is their ability to learn general reasoning patterns applicable across various fields. This is similar to recognizing effective argument structures—once understood in one context, it can be applied to law, science, philosophy, or any other discipline.</p>
<p><strong>Transfer Learning in Practice:</strong></p>
<ul>
<li>Insights gained from analyzing code can assist in mathematical proofs</li>
<li>Geometric reasoning capabilities can aid in molecular modeling</li>
<li>Strategic thinking from game-playing can enhance optimization problem-solving</li>
</ul>
<p>This cross-domain knowledge transfer significantly reduces the amount of training data needed for new tasks, resulting in more robust and adaptable solutions.</p>
<h4 id="3.-Grounding:-Linking-Symbols-to-Meaning">3. Grounding: Linking Symbols to Meaning<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#3.-Grounding:-Linking-Symbols-to-Meaning">¶</a>
</h4>
<p>One of the most compelling capabilities of foundation models is their ability to connect abstract symbols to tangible understanding. When humans encounter the term "isosceles triangle," it conjures a visual image and geometric intuitions. Foundation models are beginning to form similar associations.</p>
<p><strong>Multimodal Comprehension:</strong></p>
<ul>
<li>Connecting mathematical equations to their graphical representations</li>
<li>Linking programming code to its visual outcomes</li>
<li>Associating chemical formulas with molecular structures</li>
</ul>
<p>This grounding enables AI systems to reason more like humans do—not merely manipulating symbols but understanding the real-world significance of those symbols.</p>
<h3 id="Current-Applications-and-Success-Stories">Current Applications and Success Stories<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#Current-Applications-and-Success-Stories">¶</a>
</h3>
<h4 id="Mathematical-Theorem-Proving">Mathematical Theorem Proving<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#Mathematical-Theorem-Proving">¶</a>
</h4>
<p>Contemporary AI systems have demonstrated the ability to discover and prove mathematical theorems, occasionally producing proofs that are more concise and elegant than those developed by humans. These systems can:</p>
<ul>
<li>Generate conjectures by identifying patterns within mathematical data.</li>
<li>Construct formal proofs in a systematic manner.</li>
<li>Verify the accuracy of complex mathematical arguments.</li>
</ul>
<h4 id="Program-Synthesis-and-Code-Understanding">Program Synthesis and Code Understanding<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#Program-Synthesis-and-Code-Understanding">¶</a>
</h4>
<p>Foundation models have significantly impacted software development through:</p>
<ul>
<li>
<strong>Code Generation:</strong> Producing programs based on natural language descriptions.</li>
<li>
<strong>Bug Detection:</strong> Identifying programming errors and recommending corrections.</li>
<li>
<strong>Code Translation:</strong> Converting code between various programming languages.</li>
<li>
<strong>Documentation:</strong> Automatically generating explanations for intricate code.</li>
</ul>
<h4 id="Scientific-Discovery">Scientific Discovery<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#Scientific-Discovery">¶</a>
</h4>
<p>In the fields of chemistry and materials science, AI systems are:</p>
<ul>
<li>Predicting optimal synthetic routes for novel compounds.</li>
<li>Discovering new materials with specific desired properties.</li>
<li>Accelerating drug discovery by identifying promising molecular candidates.</li>
</ul>
<h3 id="Challenges-and-Future-Directions">Challenges and Future Directions<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#Challenges-and-Future-Directions">¶</a>
</h3>
<h4 id="The-Data-Scarcity-Problem">The Data Scarcity Problem<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#The-Data-Scarcity-Problem">¶</a>
</h4>
<p>In contrast to images or text, high-quality reasoning data is limited and costly to produce. Mathematical proofs, verified code, and scientific discoveries necessitate expert knowledge and thorough validation, creating a bottleneck in training advanced reasoning systems.</p>
<p><strong>Potential Solutions:</strong></p>
<ul>
<li>
<strong>Synthetic Data Generation:</strong> Developing artificial yet realistic problems and solutions.</li>
<li>
<strong>Self-Supervised Learning:</strong> Enabling models to learn from the inherent structure of problems.</li>
<li>
<strong>Interactive Learning:</strong> Engaging human experts to facilitate the learning process.</li>
</ul>
<h4 id="The-Need-for-High-Level-Planning">The Need for High-Level Planning<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#The-Need-for-High-Level-Planning">¶</a>
</h4>
<p>Current foundation models are proficient at next-step predictions but face challenges with long-term strategic planning. Humans typically approach complex issues by:</p>
<ol>
<li>Establishing a high-level strategy.</li>
<li>Decomposing it into manageable tasks.</li>
<li>Implementing the detailed plan.</li>
</ol>
<p>Equipping AI systems to operate at this architectural level remains a significant challenge.</p>
<h4 id="Reliability-and-Verification">Reliability and Verification<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#Reliability-and-Verification">¶</a>
</h4>
<p>As AI systems enhance their autonomous reasoning abilities, ensuring their reliability becomes imperative. We require methods to:</p>
<ul>
<li>Confirm the correctness of AI-generated proofs.</li>
<li>Validate that synthesized code performs as intended.</li>
<li>Assess scientific discoveries before their practical application.</li>
</ul>
<h3 id="The-Road-Ahead:-Implications-and-Opportunities">The Road Ahead: Implications and Opportunities<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#The-Road-Ahead:-Implications-and-Opportunities">¶</a>
</h3>
<h4 id="Education-and-Learning">Education and Learning<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#Education-and-Learning">¶</a>
</h4>
<p>Foundation models with robust reasoning capabilities have the potential to transform education by:</p>
<ul>
<li>Offering personalized tutoring that adjusts to individual learning preferences.</li>
<li>Creating interactive environments for problem-solving.</li>
<li>Generating practice problems customized to student requirements.</li>
<li>Explaining complex concepts through diverse approaches.</li>
</ul>
<h4 id="Scientific-Acceleration">Scientific Acceleration<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#Scientific-Acceleration">¶</a>
</h4>
<p>By automating routine reasoning tasks while enhancing human creativity, these systems could significantly accelerate scientific advancements:</p>
<ul>
<li>
<strong>Hypothesis Generation:</strong> Proposing innovative research avenues.</li>
<li>
<strong>Experimental Design:</strong> Refining experimental protocols.</li>
<li>
<strong>Literature Analysis:</strong> Detecting patterns across extensive research bodies.</li>
<li>
<strong>Collaborative Discovery:</strong> Fostering partnerships between humans and AI in research.</li>
</ul>
<h4 id="Ethical-Considerations">Ethical Considerations<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#Ethical-Considerations">¶</a>
</h4>
<p>As reasoning capabilities evolve, we must thoughtfully address:</p>
<ul>
<li>
<strong>Transparency:</strong> Ensuring AI reasoning processes remain interpretable.</li>
<li>
<strong>Reliability:</strong> Developing systems that gracefully handle failures and acknowledge uncertainty.</li>
<li>
<strong>Human Agency:</strong> Preserving meaningful human involvement in critical decision-making.</li>
<li>
<strong>Equity:</strong> Guaranteeing fair distribution of benefits across society.</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=3b119ddf">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Conclusion:-The-Promise-of-Intelligent-Partnership">Conclusion: The Promise of Intelligent Partnership<a class="anchor-link" href="../posts/how-ai-foundation-models-are-revolutionizing-complex-reasoning-from-game-playing-to-mathematical-discovery/#Conclusion:-The-Promise-of-Intelligent-Partnership">¶</a>
</h3>
<p>The advancement of foundation models with advanced reasoning capabilities signifies more than a technological milestone; it heralds a future where AI systems can act as true intellectual partners rather than merely tools.</p>
<p>These systems will not replace human reasoning but will enhance it, managing routine cognitive tasks and allowing humans to concentrate on creativity, judgment, and meaning-making. Future geometry students may collaborate with AI tutors capable of visualizing problems in various ways, suggesting alternative proof strategies, and providing personalized guidance.</p>
<p>As we continue to explore the frontiers of AI reasoning, we are not simply developing smarter machines; we are forging new avenues for collaboration between humans and artificial intelligence to address the intricate challenges that lie ahead.</p>
<p>The evolution from rule-based systems to today’s foundation models has been extraordinary, yet we remain in the early phases of this transformation. The coming years will likely introduce even more advanced reasoning capabilities, unlocking possibilities that are currently beyond our imagination.</p>
<p>It is clear that the future of problem-solving will rely on a partnership between human insight and artificial intelligence, combining the strengths of both to confront challenges that neither could overcome independently.</p>
<p>Citation: Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., ... &amp; Liang, P. (2022). On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258. Available at: <a href="https://arxiv.org/abs/2108.07258">https://arxiv.org/abs/2108.07258</a></p>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on
                <a href="../categories/large-language-models/">#large-language-models</a>,
                <a href="../categories/llms/">#llms</a>,
                <a href="../categories/transformers/">#transformers</a>,

        <time class="post-date" datetime="2025-06-23T01:58:34+05:45">
            2025-06-23
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/the-future-of-robotics-building-intelligent-foundation-models-for-general-purpose-robots/">The Future of Robotics: Building Intelligent Foundation Models for General-Purpose Robots</a></h2>
    </header><section class="post-excerpt"><div class="cell border-box-sizing text_cell rendered" id="cell-id=1790e718">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Introduction:-The-Vision-of-Universal-Robots">Introduction: The Vision of Universal Robots<a class="anchor-link" href="../posts/the-future-of-robotics-building-intelligent-foundation-models-for-general-purpose-robots/#Introduction:-The-Vision-of-Universal-Robots">¶</a>
</h3>
<p>Envision entering your kitchen and instructing, "Robot, prepare breakfast." The robot comprehends not only your command but also your preferences—whether you desire pancakes and coffee or toast and juice—and adapts to your kitchen layout to execute the task effectively. This scenario represents the ambitious aim behind advancing robotics foundation models.</p>
<p>Just as GPT revolutionized language processing and vision models transformed image recognition, robotics is poised for a similar foundation model revolution. Unlike text or images, robots must navigate a complex physical environment, making real-time decisions that affect their surroundings.</p>
<h3 id="Understanding-Robotics-Foundation-Models">Understanding Robotics Foundation Models<a class="anchor-link" href="../posts/the-future-of-robotics-building-intelligent-foundation-models-for-general-purpose-robots/#Understanding-Robotics-Foundation-Models">¶</a>
</h3>
<p>Foundation models can be likened to the "Swiss Army knife" of artificial intelligence. In language processing, models such as GPT manage various tasks like writing, translation, and summarization from a single trained system. Robotics foundation models aspire to provide similar versatility for physical robots.</p>
<p>These models will be trained on extensive, diverse datasets, including:</p>
<ul>
<li>
<strong>Robot interaction data</strong>: Extensive hours of robots performing diverse tasks</li>
<li>
<strong>Human demonstration videos</strong>: Learning from observing people in various activities</li>
<li>
<strong>Simulation environments</strong>: Virtual settings for safe practice</li>
<li>
<strong>Natural language descriptions</strong>: Interpreting task instructions in straightforward language</li>
</ul>
<img alt="No description has been provided for this image" src="../images/foundational_models_robotics1.png"><p class="more"><a href="../posts/the-future-of-robotics-building-intelligent-foundation-models-for-general-purpose-robots/">Read more…</a></p>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on
                <a href="../categories/large-language-models/">#large-language-models</a>,
                <a href="../categories/llms/">#llms</a>,
                <a href="../categories/transformers/">#transformers</a>,

        <time class="post-date" datetime="2025-06-23T01:26:53+05:45">
            2025-06-23
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/foundation-models-in-computer-vision-transforming-how-machines-see-and-understand-the-world/">Foundation Models in Computer Vision: Transforming How Machines See and Understand the World</a></h2>
    </header><section class="post-excerpt"><div class="cell border-box-sizing text_cell rendered" id="cell-id=2330e45c">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Introduction:-The-Vision-Revolution">Introduction: The Vision Revolution<a class="anchor-link" href="../posts/foundation-models-in-computer-vision-transforming-how-machines-see-and-understand-the-world/#Introduction:-The-Vision-Revolution">¶</a>
</h3>
<p>The goal of enabling computers to perceive the world as humans do—recognizing objects, understanding scenes, and processing complex visual information in fractions of a second—has been a long-standing pursuit in computer vision research. Foundation models are significantly advancing this objective.</p>
<p>Foundation models in computer vision signify a shift from traditional methodologies. Rather than developing distinct models for individual tasks, these robust systems learn from extensive visual datasets and can be applied across various domains, including medical diagnostics and autonomous vehicles.</p>
<h3 id="Definition-of-Vision-Foundation-Models">Definition of Vision Foundation Models<a class="anchor-link" href="../posts/foundation-models-in-computer-vision-transforming-how-machines-see-and-understand-the-world/#Definition-of-Vision-Foundation-Models">¶</a>
</h3>
<p>Vision foundation models are large-scale AI systems trained on extensive datasets comprising images and visual data. Unlike conventional computer vision models that rely on meticulously labeled data for each task, these models utilize self-supervised learning, enabling them to identify patterns in unannotated visual data.</p>
<h4 id="Key-Characteristics:">Key Characteristics:<a class="anchor-link" href="../posts/foundation-models-in-computer-vision-transforming-how-machines-see-and-understand-the-world/#Key-Characteristics:">¶</a>
</h4>
<ul>
<li>
<strong>Scale</strong>: Trained on millions to billions of images</li>
<li>
<strong>Versatility</strong>: Adaptable to various vision tasks</li>
<li>
<strong>Self-supervised learning</strong>: Minimizes reliance on manual annotations</li>
<li>
<strong>Multimodal integration</strong>: Merges visual data with text, audio, and other inputs</li>
</ul>
<img alt="No description has been provided for this image" src="../images/foundational_models_vision1.png"><p class="more"><a href="../posts/foundation-models-in-computer-vision-transforming-how-machines-see-and-understand-the-world/">Read more…</a></p>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on
                <a href="../categories/large-language-models/">#large-language-models</a>,
                <a href="../categories/llms/">#llms</a>,
                <a href="../categories/transformers/">#transformers</a>,

        <time class="post-date" datetime="2025-06-23T00:51:12+05:45">
            2025-06-23
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/how-foundation-model-is-changing-the-natural-language-processing-nlp-landscape/">How Foundation Model is changing the Natural Language Processing (NLP) landscape ?</a></h2>
    </header><section class="post-excerpt"><div class="cell border-box-sizing text_cell rendered" id="cell-id=a3548a81">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Foundation Models in Natural Language Processing: A Comprehensive Overview</strong></p>
<p><strong>The Language Revolution in AI</strong></p>
<p>Language is fundamental to human communication, influencing our thoughts, relationships, and knowledge acquisition. Every society develops complex spoken or signed languages, which children learn effortlessly. This complexity poses a significant challenge in artificial intelligence research.</p>
<p>Natural Language Processing (NLP) focuses on enabling computers to understand and generate human language. A transformative shift occurred in 2018 with the advent of foundation models, revolutionizing our approach to language technology.</p>
<img alt="No description has been provided for this image" src="../images/foundation_models_landscape.png"><p class="more"><a href="../posts/how-foundation-model-is-changing-the-natural-language-processing-nlp-landscape/">Read more…</a></p>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on
                <a href="../categories/bert/">#BERT</a>,
                <a href="../categories/foundation-models/">#foundation-models</a>,
                <a href="../categories/large-language-models/">#large-language-models</a>,
                <a href="../categories/llms/">#llms</a>,
                <a href="../categories/openai/">#openai</a>,
                <a href="../categories/transformers/">#transformers</a>,

        <time class="post-date" datetime="2025-06-12T01:03:53+05:45">
            2025-06-12
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/what-is-the-future-of-foundation-models/">What is the future of Foundation Models ?</a></h2>
    </header><section class="post-excerpt"><div class="cell border-box-sizing text_cell rendered" id="cell-id=09ec12c8">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Future-of-AI-Foundation-Models:-Who-Will-Shape-Tomorrow's-Technology?">The Future of AI Foundation Models: Who Will Shape Tomorrow's Technology?<a class="anchor-link" href="../posts/what-is-the-future-of-foundation-models/#The-Future-of-AI-Foundation-Models:-Who-Will-Shape-Tomorrow's-Technology?">¶</a>
</h2>
<h3 id="The-Early-Days-of-AI:-Understanding-Our-Current-Landscape">The Early Days of AI: Understanding Our Current Landscape<a class="anchor-link" href="../posts/what-is-the-future-of-foundation-models/#The-Early-Days-of-AI:-Understanding-Our-Current-Landscape">¶</a>
</h3>
<p>While recent advancements like ChatGPT have made headlines, we are still in the initial phase of the foundation model revolution. Picture it like the internet in 1995—we recognize the immense potential, yet we are still navigating the necessary rules, standards, and best practices.</p>
<p>At this moment, these advanced AI systems function as "research prototypes" available to the public. It's akin to taking experimental vehicles for a spin on public roads—thrilling but accompanied by uncertain risks and outcomes.</p>
<h3 id="A-Crucial-Inquiry:-Who-Will-Guide-AI's-Future?">A Crucial Inquiry: Who Will Guide AI's Future?<a class="anchor-link" href="../posts/what-is-the-future-of-foundation-models/#A-Crucial-Inquiry:-Who-Will-Guide-AI's-Future?">¶</a>
</h3>
<p>The evolution of foundation models prompts a vital question that will influence technological advancements for the next decade: <strong>Who will steer the development of AI?</strong> The answer will impact various facets of society, from job markets to democratic processes.</p>
<h3 id="The-Divide:-Industry-vs.-Academia">The Divide: Industry vs. Academia<a class="anchor-link" href="../posts/what-is-the-future-of-foundation-models/#The-Divide:-Industry-vs.-Academia">¶</a>
</h3>
<img alt="No description has been provided for this image" src="../images/foundational_models_future.png"><p class="more"><a href="../posts/what-is-the-future-of-foundation-models/">Read more…</a></p>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on
                <a href="../categories/bert/">#BERT</a>,
                <a href="../categories/foundation-models/">#foundation-models</a>,
                <a href="../categories/large-language-models/">#large-language-models</a>,
                <a href="../categories/llms/">#llms</a>,
                <a href="../categories/openai/">#openai</a>,
                <a href="../categories/transformers/">#transformers</a>,

        <time class="post-date" datetime="2025-06-10T13:02:08+05:45">
            2025-06-10
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/how-foundational-models-differs-from-other-models-such-as-machine-learning-or-deep-learning-models/">How foundational Models differs from other models such as machine learning or deep learning models ?</a></h2>
    </header><section class="post-excerpt"><div class="cell border-box-sizing text_cell rendered" id="cell-id=d28cc5f0">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Exploring-Foundation-Models:-A-Guide-to-the-AI-Revolution">Exploring Foundation Models: A Guide to the AI Revolution<a class="anchor-link" href="../posts/how-foundational-models-differs-from-other-models-such-as-machine-learning-or-deep-learning-models/#Exploring-Foundation-Models:-A-Guide-to-the-AI-Revolution">¶</a>
</h2>
<h3 id="The-Two-Forces-Shaping-AI:-Emergence-and-Homogenization">The Two Forces Shaping AI: Emergence and Homogenization<a class="anchor-link" href="../posts/how-foundational-models-differs-from-other-models-such-as-machine-learning-or-deep-learning-models/#The-Two-Forces-Shaping-AI:-Emergence-and-Homogenization">¶</a>
</h3>
<p>Artificial Intelligence has experienced a significant transformation over the last thirty years, driven by two key forces that are redefining the development and implementation of AI systems.</p>
<p><strong>Emergence</strong> refers to the natural development of capabilities during training, rather than through explicit programming. Imagine teaching a child to ride a bike; you don't dictate every movement, but through practice, the skill emerges organically.</p>
<p><strong>Homogenization</strong> indicates the adoption of similar methodologies across various challenges. Instead of creating entirely distinct solutions for each problem, we now implement standardized techniques that are applicable across multiple scenarios.</p>
<h3 id="The-Three-Stages-of-AI-Evolution">The Three Stages of AI Evolution<a class="anchor-link" href="../posts/how-foundational-models-differs-from-other-models-such-as-machine-learning-or-deep-learning-models/#The-Three-Stages-of-AI-Evolution">¶</a>
</h3>
<img alt="No description has been provided for this image" src="../images/foundation_models_difference.png"><p class="more"><a href="../posts/how-foundational-models-differs-from-other-models-such-as-machine-learning-or-deep-learning-models/">Read more…</a></p>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on

        <time class="post-date" datetime="2025-06-08T21:11:25+05:45">
            2025-06-08
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/what-are-large-language-models-llms/">What are Large Language Models (LLMs) ?</a></h2>
    </header><section class="post-excerpt"><div class="cell border-box-sizing text_cell rendered" id="cell-id=d8aa7401">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>The Evolution of Large Language Models: From Turing's Vision to the Reality of ChatGPT</strong></p>
<p><strong>A 70-Year Journey: From the Turing Test to Contemporary AI</strong></p>
<p>The journey to develop machines that genuinely grasp human language began in the 1950s with Alan Turing’s introduction of his renowned test for machine intelligence. This monumental challenge posed the question: how can we teach computers to understand the intricacies and nuances of human language?</p>
<p>Language transcends mere words; it is a complex system enriched with grammar rules, cultural contexts, implied meanings, and creative expression. Imagine attempting to convey sarcasm, poetry, or humor to someone unfamiliar with human emotions. This was the challenge engineers confronted while designing machines capable of understanding language.</p>
<p><strong>Three Stages of Evolution in Language AI</strong></p>
<p><strong>Stage 1: Statistical Language Models (1990s-2010s)</strong><br>
Early language models functioned like advanced autocomplete systems, relying on statistical patterns to predict subsequent words. For instance, if you entered "The weather is," the system would analyze millions of examples to suggest words like "nice," "cold," or "sunny" based on observed frequency patterns.<br><strong>Limitations:</strong> While these models could complete sentences, they lacked true comprehension of meaning or context beyond a few words.</p>
<p><strong>Stage 2: Neural Language Models (2010s)</strong><br>
The advent of neural networks transformed language processing, allowing models to grasp context and word relationships. For example, unlike statistical models, neural networks could discern that "bank" has different meanings in "river bank" and "savings bank" by evaluating the surrounding context.<br><strong>Breakthrough:</strong> Models like BERT (2018) significantly improved language comprehension by enabling them to read entire sentences and understand the interconnections between words.</p>
<p><strong>Stage 3: Large Language Models - The Current Revolution (2020s-Present)</strong><br>
A remarkable breakthrough emerged when researchers discovered that enlarging language models significantly enhanced their performance and granted them new capabilities.</p>
<p><strong>The Importance of Scale: Discovering the Impact of Size</strong><br>
Researchers identified that when language models exceeded specific size thresholds—transitioning from millions to hundreds of billions of parameters—extraordinary advancements occurred. These models not only excelled in existing tasks but also developed entirely new abilities.<br>
Consider it this way: imagine learning to play the piano, and upon reaching a certain level, you suddenly find yourself able to compose symphonies without formal training in composition.</p>
<p><strong>What Defines a "Large" Language Model?</strong><br>
Modern Large Language Models are characterized by:</p>
<ul>
<li>Hundreds of billions of parameters, in contrast to older models with millions.</li>
<li>Training on extensive text datasets sourced from the internet.</li>
<li>Transformer architecture that enables the processing and understanding of relationships between words over lengthy passages.</li>
</ul>
<p>For instance, GPT-3 boasts 175 billion parameters—imagine a brain with 175 billion adjustable connections, each fine-tuned through exposure to a vast array of human-written knowledge.</p>
<p><strong>Emergent Abilities: Unforeseen Capabilities</strong><br>
One of the most astonishing features is "in-context learning," which allows models to acquire new tasks simply by observing examples within a conversation.<br><strong>Example:</strong></p>
<p>If you present the model with: "Dog -&gt; Animal, Rose -&gt; Flower, Oak -&gt; ?”<br>
It can respond with: "Tree"<br>
This demonstrates its ability to recognize patterns (specific items to their categories) from the examples provided.</p>
<p><strong>Additional Emergent Abilities:</strong></p>
<ul>
<li>
<strong>Complex reasoning:</strong> Solving intricate multi-step math problems.</li>
<li>
<strong>Creative writing:</strong> Producing poetry, stories, and scripts.</li>
<li>
<strong>Code generation:</strong> Writing functional computer programs.</li>
<li>
<strong>Language translation:</strong> Converting text between languages even if not specifically trained for those translations.</li>
</ul>
<p>Summary:</p>
<p>Language models create and produce text by predicting the likelihood of a word or series of words appearing within a larger
context. This capability is particularly beneficial for tasks such as text generation and translation.</p>
<p>Large language models (LLMs) are sophisticated models that utilize extensive parameters and large datasets,
allowing them to handle longer text sequences and execute complex functions like summarization and answering questions.</p>
<p>Transformers serve as a fundamental architecture in LLMs, employing attention mechanisms to prioritize significant parts
of the input, which improves processing efficiency.</p>
<p>LLMs offer a wide range of applications, including text generation, translation, sentiment analysis, and code generation.
However, they also raise important considerations regarding costs, biases, and ethical implications.</p>
<p>Citation: Zhao, Wayne Xin, et al. "A Survey of Large Language Models." arXiv preprint arXiv:2303.18223 (2023).
arXiv: <a href="https://arxiv.org/abs/2303.18223">https://arxiv.org/abs/2303.18223</a></p>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on
                <a href="../categories/large-language-models/">#large-language-models</a>,
                <a href="../categories/llms/">#llms</a>,
                <a href="../categories/transformers/">#transformers</a>,

        <time class="post-date" datetime="2025-06-08T19:46:53+05:45">
            2025-06-08
        </time></footer></article><article class="post post"><header class="post-header"><h2 class="post-title"><a href="../posts/understanding-high-bias-in-machine-learning-with-real-world-example/">Understanding High Bias in Machine Learning with Real-World Example</a></h2>
    </header><section class="post-excerpt"><div class="cell border-box-sizing text_cell rendered" id="cell-id=40aa6e5c">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>High bias in machine learning results in underfitting, characterized by the model making oversimplified assumptions about the relationships within the data. This leads to subpar performance on both training and test datasets, demonstrating that the model does not possess the necessary complexity to capture the underlying patterns.</p>
<p>In this example, we will check house price prediction using two methods:</p>
<ol>
<li>Linear Regression: The simple linear model does not adequately capture the complex relationships between features and house prices.</li>
<li>Polynomial Regression: The PolynomialFeatures step enhances the dataset by generating polynomial and interaction terms from the original features. For instance, when you have a feature x with a degree of 2, it will produce new features such as x, x², and cross-terms like x1 * x2. This approach enables a linear regression model to effectively capture non-linear relationships.</li>
</ol>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=3cfe78df">
<div class="input">
<div class="prompt input_prompt">In [31]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sklearn.datasets</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pipeline</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=b700af4d">
<div class="input">
<div class="prompt input_prompt">In [21]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">house_price_dataset</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fetch_california_housing</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=54eaaab7">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=a952b9bf">
<div class="input">
<div class="prompt input_prompt">In [22]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">house_price_dataset</span><span class="o">.</span><span class="n">DESCR</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>.. _california_housing_dataset:

California Housing dataset
--------------------------

**Data Set Characteristics:**

    :Number of Instances: 20640

    :Number of Attributes: 8 numeric, predictive attributes and the target

    :Attribute Information:
        - MedInc        median income in block group
        - HouseAge      median house age in block group
        - AveRooms      average number of rooms per household
        - AveBedrms     average number of bedrooms per household
        - Population    block group population
        - AveOccup      average number of household members
        - Latitude      block group latitude
        - Longitude     block group longitude

    :Missing Attribute Values: None

This dataset was obtained from the StatLib repository.
https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html

The target variable is the median house value for California districts,
expressed in hundreds of thousands of dollars ($100,000).

This dataset was derived from the 1990 U.S. census, using one row per census
block group. A block group is the smallest geographical unit for which the U.S.
Census Bureau publishes sample data (a block group typically has a population
of 600 to 3,000 people).

A household is a group of people residing within a home. Since the average
number of rooms and bedrooms in this dataset are provided per household, these
columns may take surprisingly large values for block groups with few households
and many empty houses, such as vacation resorts.

It can be downloaded/loaded using the
:func:`sklearn.datasets.fetch_california_housing` function.

.. topic:: References

    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,
      Statistics and Probability Letters, 33 (1997) 291-297

</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=9751a745">
<div class="input">
<div class="prompt input_prompt">In [23]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Loading the dataset to a pandas dataframe</span>
<span class="n">df_house_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">house_price_dataset</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">house_price_dataset</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=db6e95bf">
<div class="input">
<div class="prompt input_prompt">In [24]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">df_house_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt output_prompt">Out[24]:</div>
<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead><tr style="text-align: right;">
<th></th>
<th>MedInc</th>
<th>HouseAge</th>
<th>AveRooms</th>
<th>AveBedrms</th>
<th>Population</th>
<th>AveOccup</th>
<th>Latitude</th>
<th>Longitude</th>
</tr></thead>
<tbody>
<tr>
<th>0</th>
<td>8.3252</td>
<td>41.0</td>
<td>6.984127</td>
<td>1.023810</td>
<td>322.0</td>
<td>2.555556</td>
<td>37.88</td>
<td>-122.23</td>
</tr>
<tr>
<th>1</th>
<td>8.3014</td>
<td>21.0</td>
<td>6.238137</td>
<td>0.971880</td>
<td>2401.0</td>
<td>2.109842</td>
<td>37.86</td>
<td>-122.22</td>
</tr>
<tr>
<th>2</th>
<td>7.2574</td>
<td>52.0</td>
<td>8.288136</td>
<td>1.073446</td>
<td>496.0</td>
<td>2.802260</td>
<td>37.85</td>
<td>-122.24</td>
</tr>
<tr>
<th>3</th>
<td>5.6431</td>
<td>52.0</td>
<td>5.817352</td>
<td>1.073059</td>
<td>558.0</td>
<td>2.547945</td>
<td>37.85</td>
<td>-122.25</td>
</tr>
<tr>
<th>4</th>
<td>3.8462</td>
<td>52.0</td>
<td>6.281853</td>
<td>1.081081</td>
<td>565.0</td>
<td>2.181467</td>
<td>37.85</td>
<td>-122.25</td>
</tr>
</tbody>
</table>
</div></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=ac8cfa52">
<div class="input">
<div class="prompt input_prompt">In [25]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># add the target column</span>
<span class="c1"># target is median house value in block group (in $100,000s).</span>
<span class="n">df_house_data</span><span class="p">[</span><span class="s1">'price'</span><span class="p">]</span> <span class="o">=</span> <span class="n">house_price_dataset</span><span class="o">.</span><span class="n">target</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=060b5817">
<div class="input">
<div class="prompt input_prompt">In [26]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">df_house_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt output_prompt">Out[26]:</div>
<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead><tr style="text-align: right;">
<th></th>
<th>MedInc</th>
<th>HouseAge</th>
<th>AveRooms</th>
<th>AveBedrms</th>
<th>Population</th>
<th>AveOccup</th>
<th>Latitude</th>
<th>Longitude</th>
<th>price</th>
</tr></thead>
<tbody>
<tr>
<th>0</th>
<td>8.3252</td>
<td>41.0</td>
<td>6.984127</td>
<td>1.023810</td>
<td>322.0</td>
<td>2.555556</td>
<td>37.88</td>
<td>-122.23</td>
<td>4.526</td>
</tr>
<tr>
<th>1</th>
<td>8.3014</td>
<td>21.0</td>
<td>6.238137</td>
<td>0.971880</td>
<td>2401.0</td>
<td>2.109842</td>
<td>37.86</td>
<td>-122.22</td>
<td>3.585</td>
</tr>
<tr>
<th>2</th>
<td>7.2574</td>
<td>52.0</td>
<td>8.288136</td>
<td>1.073446</td>
<td>496.0</td>
<td>2.802260</td>
<td>37.85</td>
<td>-122.24</td>
<td>3.521</td>
</tr>
<tr>
<th>3</th>
<td>5.6431</td>
<td>52.0</td>
<td>5.817352</td>
<td>1.073059</td>
<td>558.0</td>
<td>2.547945</td>
<td>37.85</td>
<td>-122.25</td>
<td>3.413</td>
</tr>
<tr>
<th>4</th>
<td>3.8462</td>
<td>52.0</td>
<td>6.281853</td>
<td>1.081081</td>
<td>565.0</td>
<td>2.181467</td>
<td>37.85</td>
<td>-122.25</td>
<td>3.422</td>
</tr>
</tbody>
</table>
</div></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=15132a2f">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="House-Price-Prediction-Using-Linear-Regression">House Price Prediction Using Linear Regression<a class="anchor-link" href="../posts/understanding-high-bias-in-machine-learning-with-real-world-example/#House-Price-Prediction-Using-Linear-Regression">¶</a>
</h5>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=86ef8746">
<div class="input">
<div class="prompt input_prompt">In [34]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Prepare data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_house_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'price'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_house_data</span><span class="p">[</span><span class="s1">'price'</span><span class="p">]</span>

<span class="c1"># Split and scale</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Train linear model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluate</span>
<span class="n">train_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="n">test_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Training MSE:"</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Test MSE:"</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred</span><span class="p">))</span>

<span class="n">train_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">test_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training R² Score: </span><span class="si">{</span><span class="n">train_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Test R² Score: </span><span class="si">{</span><span class="n">test_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Training MSE: 0.5240457125963887
Test MSE: 0.5261093658365182
Training R² Score: 0.6081
Test R² Score: 0.5980
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=aa6f2c1f">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="House-Price-Prediction-Using-Polynomial-Regression">House Price Prediction Using Polynomial Regression<a class="anchor-link" href="../posts/understanding-high-bias-in-machine-learning-with-real-world-example/#House-Price-Prediction-Using-Polynomial-Regression">¶</a>
</h5>
<ul>
<li>Observations:<ul>
<li>
<p>The mean squared error is decreased in test set.</p>
</li>
<li>
<p>The R² score is increased in test set.</p>
<p>-- R² Interpretation: An R-squared value of 0.75 indicates that 75% of the variation in house prices can be attributed to factors such as square footage, location, and the amenities included in the model.</p>
</li>
</ul>
</li>
</ul>
<p>Why Use both <code>PolynomialFeatures</code> and <code>LinearRegression</code> in the Pipeline:</p>
<pre><code>- The first PolynomialFeatures transformation creates a more complex feature space.
- The LinearRegression then fits a linear model to these non-linear features.
- This effectively allows a linear model to approximate non-linear relationships.</code></pre>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=b5e52638">
<div class="input">
<div class="prompt input_prompt">In [35]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">polynomial_regression_model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="c1"># Create pipeline</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">'scaler'</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="s1">'poly'</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="n">degree</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">'linear'</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())</span>
    <span class="p">])</span>
   
    <span class="c1"># Fit and evaluate</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Evaluate</span>
    <span class="n">train_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
    <span class="n">test_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">"Training MSE:"</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_pred</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Test MSE:"</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred</span><span class="p">))</span>

    <span class="n">train_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">test_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training R² Score: </span><span class="si">{</span><span class="n">train_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Test R² Score: </span><span class="si">{</span><span class="n">test_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train_poly</span><span class="p">,</span> <span class="n">X_test_poly</span>

<span class="c1"># Example usage with housing data</span>
<span class="n">model_poly</span><span class="p">,</span> <span class="n">X_train_poly</span><span class="p">,</span> <span class="n">X_test_poly</span> <span class="o">=</span> <span class="n">polynomial_regression_model</span><span class="p">(</span>
    <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">X_test_scaled</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Training MSE: 0.4219834148836872
Test MSE: 0.42363567392919027
Training R² Score: 0.6844
Test R² Score: 0.6763
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=011b7ec6">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
    </section><footer class="post-meta">
                Sijan Bhandari

        on
                <a href="../categories/high-bias/">#high-bias</a>,
                <a href="../categories/underfitting/">#underfitting</a>,

        <time class="post-date" datetime="2025-01-25T20:31:28+05:45">
            2025-01-25
        </time></footer></article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="next">
                <a href="index-5.html" rel="next">Older posts</a>
            </li>
        </ul></nav><script>var disqus_shortname="blog-sijanb-com-np";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha384-3lJUsx1TJHt7BA4udB5KPnDrlkO8T6J6v/op7ui0BbCjvZ9WqV4Xm6DTP6kQ/iBH" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script></main><footer class="site-footer clearfix"><section class="poweredby">Contents © 2025         <a href="mailto:sijanonly@gmail.com">Sijan Bhandari</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         </section></footer>
</div>

    <script type="text/javascript" src="../assets/js/jquery.js"></script><script type="text/javascript" src="../assets/js/jquery.fitvids.js"></script><script type="text/javascript" src="../assets/js/index.js"></script><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-116715433-2"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-116715433-2');
</script>
</body>
</html>
