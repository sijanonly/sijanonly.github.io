{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (k-NN) is one of the classification algorithms in Machine learing. Since, K-NN simply memories or stores the rules in memory, we can also say that it does not learn the mapping function(f) between inputs and labels. \n",
    "\n",
    "The kNN algorithm can be summarized in following four steps:\n",
    "\n",
    "    1. Compute distance between the test point and each of the training points\n",
    "    2. Sort the distances in descending order\n",
    "    3. Pick 'k' nearest neighbors from the sorted items\n",
    "    4. Apply majority vote of labels for classification or averaging of label values for regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going to implementation, let us build some standard notation so that it is easier to follow the code in the implementation section (next post):\n",
    "\n",
    "              X_training = given training data\n",
    "              Y = labels for your given training data\n",
    "              X_test = new data (For which we need to predict the labels)\n",
    "              \n",
    "\n",
    "The whole algorithm can be divided into three major steps:\n",
    "\n",
    "   1. Finding most nearest neighbors (similar data instances) from your training data for a given test data (X_test)\n",
    "   \n",
    "          Let's say we have total 20 training data, and you find out 4 training instances as nearest neighbors for\n",
    "          one of your test data\n",
    "      \n",
    "   2. Once you get the nearest neighbors from your training data, collect all the labels of your selected training\n",
    "      data\n",
    "      \n",
    "          In our case, we have 4 training instances as nearest neighbors. So, we will collect labels for all\n",
    "          these 4 training data. \n",
    "      \n",
    "   3. Finally, predict the label of your test data (X_test) based on majority count.\n",
    "   \n",
    "   \n",
    "          In our case, suppose 3 out of 4 training instances have the same label. Then, the majority count\n",
    "          will assign the label to new data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `K` defines the number of neighbors that the algorithm will collect for making the prediction of your new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TEASER_END -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, we have a data set of a fruits with features : weight and height and labels as \"Apple, Peach, Pear\" as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Height(cm)</td><td>Weight(gm)</td><td>Class</td></tr>\n",
       "<tr><td>16        </td><td>160       </td><td>Pear </td></tr>\n",
       "<tr><td>14        </td><td>159       </td><td>Pear </td></tr>\n",
       "<tr><td>7         </td><td>90        </td><td>Apple</td></tr>\n",
       "<tr><td>8         </td><td>95        </td><td>Apple</td></tr>\n",
       "<tr><td>15        </td><td>165       </td><td>Pear </td></tr>\n",
       "<tr><td>4         </td><td>150       </td><td>Peach</td></tr>\n",
       "<tr><td>5         </td><td>145       </td><td>Peach</td></tr>\n",
       "<tr><td>7.5       </td><td>100       </td><td>Apple</td></tr>\n",
       "<tr><td>6         </td><td>144       </td><td>Peach</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "table = [[\"Height(cm)\",\"Weight(gm)\",\"Class\"],\n",
    "         [16, 160, 'Pear'],\n",
    "         [14, 159, 'Pear'],\n",
    "         [7, 90, 'Apple'],\n",
    "         [8, 95, 'Apple'],\n",
    "         [15, 165, 'Pear'],\n",
    "         [4, 150, 'Peach'],\n",
    "         [5, 145, 'Peach'],\n",
    "         [7.5, 100, 'Apple'],\n",
    "         [6, 144, 'Peach'],\n",
    "        \n",
    "        \n",
    "        ]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, suppose we have a machine to classify fruit based on 'weight' and 'height' information. Let's assume a new\n",
    "entry has following features\n",
    "\n",
    "         Height : 10 cm\n",
    "         Weight : 170 gm\n",
    "         \n",
    "Which class this new student belongs to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us use some distance measure between this new point and all the training data points as follows:\n",
    "\n",
    "   `sqrt((10-16)^2 + (170-160)^2) = 11.66`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def distance(p1, p2):\n",
    "    sq_distance = (p1[0] - p2[0])**2 + (p1[1] - p2[1])**2\n",
    "    return math.ceil(sq_distance**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Height(cm)</td><td>Weight(kg)</td><td>Class   </td><td>Distance</td></tr>\n",
       "<tr><td>169       </td><td>60        </td><td>Asian   </td><td>6       </td></tr>\n",
       "<tr><td>171       </td><td>59        </td><td>Asian   </td><td>7       </td></tr>\n",
       "<tr><td>172       </td><td>70        </td><td>European</td><td>7       </td></tr>\n",
       "<tr><td>179       </td><td>69        </td><td>European</td><td>12      </td></tr>\n",
       "<tr><td>170       </td><td>75        </td><td>Asian   </td><td>8       </td></tr>\n",
       "<tr><td>175       </td><td>80        </td><td>American</td><td>17      </td></tr>\n",
       "<tr><td>176       </td><td>79        </td><td>American</td><td>17      </td></tr>\n",
       "<tr><td>180       </td><td>71        </td><td>European</td><td>14      </td></tr>\n",
       "<tr><td>171       </td><td>76        </td><td>American</td><td>12      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = [[\"Height(cm)\",\"Weight(kg)\",\"Class\", \"Distance\"],\n",
    "         [16, 160, 'Pear', distance([16, 160], [10, 170])],\n",
    "         [14, 159, 'Pear', distance([14, 159], [168, 65])],\n",
    "         [7, 90, 'Apple', distance([7, 90], [168, 65])],\n",
    "         [8, 95, 'Apple', distance([8, 95], [168, 65])],\n",
    "         [15, 165, 'Pear', distance([15, 165], [168, 65])],\n",
    "         [4, 150, 'Peach', distance([4, 150], [168, 65])],\n",
    "         [5, 145, 'Peach', distance([5, 145], [168, 65])],\n",
    "         [7.5, 100, 'Apple', distance([7.5, 100], [168, 65])],\n",
    "         [6, 144, 'Peach', distance([[6, 144], [168, 65])],\n",
    "        \n",
    "        \n",
    "        ]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result table, let's select k=3, neighbors having minimal distance(nearest points)\n",
    "\n",
    "     a. 169 \t60 \tAsian \t      6 \n",
    "     b. 171 \t59 \tAsian \t      7 \n",
    "     c. 172 \t70 \tEuropean    \t7 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all possible labels in our final result is : ['Asian', 'Asian', 'European']\n",
    "\n",
    "With majority vote, we can classify the new student as 'Asian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nikola": {
   "category": "",
   "date": "2019-04-27 00:16:44 UTC+05:45",
   "description": "",
   "link": "",
   "slug": "how-k-nearest-neighbors-works",
   "tags": "kNN, machine-learning",
   "title": "How k-Nearest Neighbors works?",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
