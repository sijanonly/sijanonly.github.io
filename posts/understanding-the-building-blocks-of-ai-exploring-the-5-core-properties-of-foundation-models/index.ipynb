{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a102a9",
   "metadata": {},
   "source": [
    "<img src='/images/foundation_models_blocks1.png'>\n",
    "\n",
    "<img src='/images/foundation_models_blocks2.png'>\n",
    "\n",
    "<!-- TEASER_END -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0686ca9",
   "metadata": {},
   "source": [
    "**What Are Foundation Models?**\n",
    "\n",
    " **A New Era of AI** \n",
    " Have you ever been amazed by an AI that can write a short story, answer your complex questions, or even create a stunning piece of art from just a few words? These aren't just cool party tricks; they're the result of a new and powerful paradigm in artificial intelligence known as **foundation models**. These are massive AI models, often trained on a vast amount of data, that serve as a \"foundation\" for a wide range of more specific tasks. Think of them like a master apprentice who has read every book in the world, seen every painting, and listened to every song. They have a deep, broad understanding that can be applied to almost anything. BERT and GPT-3 are great examples that have shown incredible results in understanding human language, while DALL-E has demonstrated a flair for visual creativity. But what exactly makes these models so special? What are the key ingredients that allow them to achieve such remarkable feats? \n",
    "\n",
    " **What Makes a Model \"Foundational\"?** \n",
    " It's not just about being big or having a lot of data. A true foundation model possesses a set of specific, desirable qualities that enable it to learn and generalize so effectively. The authors of the paper we’re discussing, Drew A. Hudson et al., identify five key properties: **expressivity**, **scalability**, **multimodality**, **memory capacity**, and **compositionality**. These aren't just technical terms; they are the fundamental building blocks that allow these models to distill knowledge, represent it efficiently, and apply it to new, unforeseen situations. Let’s dive into each of these properties to understand what makes them so crucial. \n",
    "\n",
    " ---\n",
    "\n",
    "**The 5 Core Properties** \n",
    " \n",
    " **The Five Essential Properties of a Foundation Model** \n",
    " \n",
    " **1. Expressivity: Capturing the World's Richness** \n",
    " Expressivity is a model's ability to represent and model the complex data it's trained on. Imagine trying to paint a detailed portrait of a person. You need a brush that's capable of capturing all the nuances—the subtle shades, the texture of the skin, the sparkle in the eyes. In the same way, a foundation model needs to be expressive enough to capture the intricacies of natural information, whether it's the high-dimensional chaos of an image or the delicate, hierarchical structure of human language. \n",
    " \n",
    " **The Importance of Depth and Inductive Biases** \n",
    " One of the biggest drivers of expressivity in modern networks is their sheer depth. We’re talking about models with a large number of stacked layers. The more layers, the more powerful and flexible the model becomes at forming a hierarchical representation of information, allowing it to generalize to new, unseen examples. This is where the concept of **inductive biases** comes in. These are structural assumptions about the data that help a model learn more efficiently. For instance, a convolutional neural network (CNN) is designed with an inductive bias for spatially-invariant information, making it perfect for images, while recurrent neural networks (RNNs) are great for sequential data like language. \n",
    " \n",
    " **The Rise of Transformers and Attention** \n",
    " And then came transformers.  The transformer network, with its groundbreaking self-attention mechanism, changed the game by being able to capture long-range dependencies in data. This is a game-changer because it allows the model to see the big picture. For example, in the sentence \"She ate the ice-cream with a spoon,\" the model can directly link \"ate\" and \"spoon,\" no matter how far apart they are. This dynamic, adaptable computation is what makes transformers so generally applicable and powerful across a wide range of problems. We've seen a shift from task-specific models to more general-purpose architectures that \"let the data speak for itself.\" While specialized models might learn faster on specific tasks, general-purpose models can scale to higher data volumes and adapt to diverse domains, which is a much more promising approach for the future of AI. \n",
    " \n",
    " **2. Scalability: Growing with Data and Compute** \n",
    " Closely related to expressivity is scalability. In a world where we’re generating a mind-boggling amount of data and computer hardware is getting stronger by the minute, foundation models need to be able to keep up. They must be scalable across all dimensions, including their size, training time, number of parameters, and the amount of data they can process. Think of it like this: if you have a massive library of books, you need a system that can not only fit all those books but also quickly and efficiently catalog, organize, and retrieve information from them. \n",
    " \n",
    " **The Need for Efficient Optimization and Hardware Compatibility** \n",
    " A scalable model should be robust and easy to train, even with noisy or imperfect data. It needs to be resilient to issues like \"vanishing\" or \"exploding\" gradients, which are common problems in deep learning that can stop a model from learning effectively. It also needs to be easy to adapt to new tasks without \"catastrophic forgetting\"—the phenomenon where a model loses its old knowledge when it learns something new. From a practical standpoint, a model must also be designed to take full advantage of modern hardware. This is where things like **parallelizability** come in. Transformers, for example, are highly parallelizable, which is a major reason for their success over older architectures. The future of foundation models will likely see them co-adapting with hardware advancements, leveraging properties like computational sparsity to become even more efficient. \n",
    " \n",
    " **3. Multimodality: Connecting Different Worlds** \n",
    " For a long time, different fields of AI—like computer vision and natural language processing (NLP)—worked in isolation. Multimodality is all about breaking down those walls and creating a single model that can understand and connect various types of data. It’s like teaching a student to not only read a book but also to look at a picture and hear a song, and then to understand how all of those things are related. Multimodality is a crucial component of true intelligence. Language becomes more meaningful when it’s grounded in a real-world environment, and vision becomes richer when it’s linked to semantic concepts. \n",
    " \n",
    " **Breaking Down the Silos: Vision, Language, and Beyond** \n",
    " Foundation models are ideal for this task because they can distill information from different sources—be it text, images, or audio—into a single, shared representation. This shared representation allows the model to understand the full range of interconnections between these different data types. While a lot of progress has been made in aligning vision and language, there's still a lot of room for exploration. We’re on the verge of creating models that can not only describe a picture but also understand the deeper context and relationships within it. \n",
    " \n",
    " **The Challenge of Multimodal Interaction** \n",
    " A key question in multimodal models is how much to specialize or share. Should a model use completely separate components for each data type or should it share parameters? Another challenge is figuring out when and how to merge these different data spaces. Should you merge them early on, reasoning over multiple modalities at once, or should you keep them separate until the very end? The ideal approach is still an open research question, and it's one of the most exciting areas in the field right now. \n",
    " \n",
    " **4. Memory Capacity: Storing and Retrieving Knowledge** \n",
    " A foundation model, with its vast training data, accumulates an incredible amount of knowledge, both a broad understanding of the world and specific niche facts. Storing all this information is no easy task. It’s not enough to just remember things; a model also needs an effective way to access, retrieve, and manipulate that knowledge. \n",
    " \n",
    " **Implicit vs. Explicit Knowledge** \n",
    " An important distinction is between **implicit knowledge**, which is baked directly into the model's weights during training, and **explicit knowledge**, which is stored in an external memory. Think of implicit knowledge as your general understanding of how the world works, and explicit knowledge as specific facts you can look up in a notebook. Decoupling these two types of knowledge has some major advantages. It prevents the model's size from ballooning to an unmanageable degree, it improves the model’s reliability by making its knowledge traceable, and it allows for easier updates. If a fact changes, you just update the external memory, without having to retrain the entire model. \n",
    " \n",
    " **The Power of Retrieval and Knowledge Manipulation** \n",
    " There are various ways a model can retrieve this information. Some models use explicit prompts to query their own knowledge, while others use a separate retrieval system that pulls information from unstructured text repositories or structured knowledge graphs. However, there's a trade-off here. While retrieval is great for memorization, over-relying on it can hinder a model’s ability to learn abstract representations and generalize. A model that has to work with a more bounded memory might learn to distill key insights more effectively. Finally, since knowledge is dynamic, a truly effective model must be able to update and manipulate its knowledge over time. What was true yesterday may not be today, and a foundation model needs to be able to adapt to those changes. \n",
    " \n",
    " **5. Compositionality: Generalizing to the Unknown** \n",
    " Finally, we have compositionality. This is a core principle of human intelligence—the idea that we can understand the meaning of a whole by understanding its parts and the rules for combining them. It's what allows us to generalize to new situations and problems. Think of it like a LEGO set.  You can take a handful of basic bricks and, by combining them in different ways, build a spaceship, a castle, or a car. This is the essence of compositionality. It can be reflected at the model level, the computation level, the training process, and even in the learned representation itself. \n",
    " \n",
    " **From Symbolic AI to Modern Models** \n",
    " While many modern models have focused on creating monolithic, all-encompassing representations, a better path forward lies in finding a balance between contextuality and compositionality. We want models that can both understand the nuances of a phrase like “red wine” (which is not just “red” plus “wine”) and also be able to generalize by combining individual concepts into new ideas. This is why researchers are exploring structured, object-oriented representations that can identify entities and their relationships, enabling stronger out-of-distribution generalization. \n",
    "\n",
    "---\n",
    "\n",
    "**Conclusion** \n",
    " **Putting It All Together: The Future of Foundation Models** \n",
    " Foundation models are transforming the landscape of artificial intelligence, and it's the combination of these five core properties that makes them so revolutionary. Expressivity allows them to capture the richness of the world, scalability ensures they can grow with the available data and compute, multimodality helps them connect different domains, memory capacity gives them the ability to store and retrieve a vast amount of knowledge, and compositionality is the key to generalizing to novel tasks and environments. As researchers continue to push the boundaries of these properties, we can expect to see AI models that are not only more powerful but also more versatile, reliable, and capable of addressing some of the world's most complex challenges. The journey is just beginning, and these five properties are our roadmap to the future. \n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6e7c64",
   "metadata": {},
   "source": [
    "**FAQs about Foundation Models**\n",
    "\n",
    " **1. What is the main difference between a foundation model and a regular AI model?** \\<br\\> A foundation model is typically much larger, trained on a massive amount of broad data, and designed to be a versatile base for many different tasks, while a regular AI model is often smaller and trained specifically for a single, narrow task. \n",
    "\n",
    " **2. How does \"compositionality\" in AI relate to human intelligence?** \\<br\\> Compositionality is a core principle of human thought, allowing us to combine basic concepts to understand new ones (like a \"red car,\" even if we've never seen one). In AI, it's the ability of a model to generalize by understanding and recombining its learned parts, just as we do. \n",
    "\n",
    " **3. Why is \"multimodality\" so important for foundation models?** \\<br\\> Multimodality is crucial because the real world is inherently multimodal. To truly understand concepts and the relationships between them, a model needs to process information from different sources like text, images, and sound, just as humans do. \n",
    "\n",
    " **4. What does \"scalability\" mean in a practical sense for a foundation model?** \\<br\\> Practically, scalability means the model can handle a huge increase in data and still learn effectively. It also means the model is designed to be efficient with modern hardware, allowing for faster training and deployment. \n",
    " \n",
    " **5. What is the difference between implicit and explicit memory in foundation models?** \\<br\\> Implicit memory is knowledge stored within the model's internal weights, while explicit memory is stored in an external database. Implicit memory gives the model a broad, general understanding, while explicit memory allows for the storage and easy retrieval of specific facts, making updates much simpler. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb16cbe3",
   "metadata": {},
   "source": [
    "Citation: Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., ... & Liang, P. (2022). On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258. Available at: https://arxiv.org/abs/2108.07258"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "env": {},
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "nikola": {
   "category": "",
   "date": "2025-08-17 18:15:57 UTC+05:45",
   "description": "",
   "link": "",
   "slug": "understanding-the-building-blocks-of-ai-exploring-the-5-core-properties-of-foundation-models",
   "tags": "large-language-models,llms,transformers",
   "title": "Understanding the Building Blocks of AI: Exploring the 5 Core Properties of Foundation Models",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
