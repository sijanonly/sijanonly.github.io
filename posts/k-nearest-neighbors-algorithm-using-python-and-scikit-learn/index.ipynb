{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K nearest Neighbors (kNN) works based on calculating distance between given test data point and all the training samples. We, then, collect first K closest points from training set and the majority vote gives you the predicted class for a given test data point.\n",
    "\n",
    "For more intuitive explanation, please follow previous post :\n",
    "\n",
    "   > [How kNN works ?](https://sijanb.com.np/posts/how-k-nearest-neighbors-works/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# making results reproducible\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>ALCOHOL_LEVEL</th>\n",
       "      <th>MALIC_ACID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLASS  ALCOHOL_LEVEL  MALIC_ACID\n",
       "0      1          14.23        1.71\n",
       "1      1          13.20        1.78\n",
       "2      1          13.16        2.36\n",
       "3      1          14.37        1.95\n",
       "4      1          13.24        2.59"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None, sep=',')\n",
    "\n",
    "df.columns = ['CLASS', 'ALCOHOL_LEVEL', 'MALIC_ACID', 'ASH', 'ALCALINITY','MAGNESIUM', 'PHENOLS', \n",
    "              'FLAVANOIDS', 'NON_FLAVANOID_PHENOL', 'PROANTHOCYANINS', 'COLOR_INTENSITY', \n",
    "              'HUE', 'OD280/OD315_DILUTED','PROLINE']\n",
    "\n",
    "# Let us use only two features : 'ALCOHOL_LEVEL', 'MALIC_ACID' for this problem\n",
    "df = df[['CLASS', 'ALCOHOL_LEVEL', 'MALIC_ACID']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class distribution looks okay; not so imbalanced.\n",
    "df['CLASS'].value_counts().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TEASER_END -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using 10% of the data for the testing purpose\n",
    "\n",
    "train_sample_idx = np.random.choice(df.index, size=int(df.shape[0]*0.9), replace=False)\n",
    "train_data, test_data = df.iloc[train_sample_idx], df.drop(train_sample_idx)\n",
    "\n",
    "# get features and label from train/test data\n",
    "X_train, y_train = train_data.drop('CLASS', axis=1), train_data['CLASS']\n",
    "X_test, y_test = test_data.drop('CLASS', axis=1), test_data['CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 2), (18, 2))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using Python from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vector1, vector2):\n",
    "    '''calculate the euclidean distance\n",
    "    input: numpy.arrays or lists\n",
    "    return: euclidean distance\n",
    "    '''\n",
    "    dist = [(a - b)**2 for a, b in zip(vector1, vector2)]\n",
    "    dist = math.sqrt(sum(dist))\n",
    "    return dist\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, K):\n",
    "        self.K = K\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def predict_instance(self, test_instance):\n",
    "        inputs = self.X_train.copy()\n",
    "        # calculate L2 norm between all training points and given test_point\n",
    "        inputs['distance'] = np.linalg.norm(X_train.values-test_instance.values, axis=1)\n",
    "        \n",
    "        # concatenate inputs and labels before sorting the distances\n",
    "        inputs = pd.concat([inputs, self.y_train], axis=1)\n",
    "\n",
    "        # sort based on distance\n",
    "        inputs = inputs.sort_values('distance', ascending=True)\n",
    "\n",
    "        # pick k neighbors\n",
    "        neighbors = inputs.head(self.K)\n",
    "\n",
    "        # get list from dataframe column\n",
    "        classes = neighbors['CLASS'].tolist()\n",
    "\n",
    "        # create counter of labels\n",
    "        majority_count = Counter(classes)\n",
    "        \n",
    "        return majority_count.most_common(1).pop()[0]\n",
    "        \n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        predictions = np.zeros(X_test.shape[0])\n",
    "        # we want out index to be start from 0\n",
    "        X_test.reset_index(drop=True, inplace=True)\n",
    "        for index, row in X_test.iterrows():\n",
    "            predictions[index] = self.predict_instance(row)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(3)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = knn.predict(X_test)\n",
    "true_values = y_test.to_numpy()\n",
    "accuracy = np.mean(predictions == true_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_sklearn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_sklearn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = knn_sklearn.predict(X_test)\n",
    "accuracy = np.mean(predictions == true_values)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nikola": {
   "category": "",
   "date": "2020-05-02 15:23:27 UTC+05:45",
   "description": "",
   "link": "",
   "slug": "k-nearest-neighbors-algorithm-using-python-and-scikit-learn",
   "tags": "kNN, machine-learning",
   "title": "K-Nearest Neighbors Algorithm using Python and Scikit-Learn",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
