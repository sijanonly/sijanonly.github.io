{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numba\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# making results reproducible\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teaser\n",
    "\n",
    "Let us first see a small example. We will calculate the sum of inverse square root between 1 to 10000, using basic pure python method and using Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87 ms ± 48.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 sum([1./math.sqrt(i) for i in range(1,n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.7 µs ± 8.09 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 np.sum(1./np.sqrt(np.arange(1,n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Numpy vectorized calculation is 35 times faster than pure python in this example'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Numpy vectorized calculation is {:.0f} times faster than pure python in this example'.format(1.87*1000/52.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using wine dataset for kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>ALCOHOL_LEVEL</th>\n",
       "      <th>MALIC_ACID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLASS  ALCOHOL_LEVEL  MALIC_ACID\n",
       "0      1          14.23        1.71\n",
       "1      1          13.20        1.78\n",
       "2      1          13.16        2.36\n",
       "3      1          14.37        1.95\n",
       "4      1          13.24        2.59"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None, sep=',')\n",
    "\n",
    "df.columns = ['CLASS', 'ALCOHOL_LEVEL', 'MALIC_ACID', 'ASH', 'ALCALINITY','MAGNESIUM', 'PHENOLS', \n",
    "              'FLAVANOIDS', 'NON_FLAVANOID_PHENOL', 'PROANTHOCYANINS', 'COLOR_INTENSITY', \n",
    "              'HUE', 'OD280/OD315_DILUTED','PROLINE']\n",
    "\n",
    "# Let us use only two features : 'ALCOHOL_LEVEL', 'MALIC_ACID' for this problem\n",
    "df = df[['CLASS', 'ALCOHOL_LEVEL', 'MALIC_ACID']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using 10% of the data for the testing purpose\n",
    "\n",
    "train_sample_idx = np.random.choice(df.index, size=int(df.shape[0]*0.9), replace=False)\n",
    "train_data, test_data = df.iloc[train_sample_idx], df.drop(train_sample_idx)\n",
    "\n",
    "# get features and label from train/test data\n",
    "X_train, y_train = train_data.drop('CLASS', axis=1), train_data['CLASS']\n",
    "X_test, y_test = test_data.drop('CLASS', axis=1), test_data['CLASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. kNN using Python from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def euclidean_distance(vector1, vector2):\n",
    "    '''calculate the euclidean distance, core python method\n",
    "    input: numpy.arrays or lists\n",
    "    return: euclidean distance\n",
    "    '''\n",
    "    dist = [(a - b)**2 for a, b in zip(vector1, vector2)]\n",
    "    dist = math.sqrt(sum(dist))\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_instance(inputs, labels, test_instance, k):\n",
    "    inputs['distance'] = inputs.apply(euclidean_distance, vector2=test_instance, axis=1)\n",
    "    \n",
    "    # concatenate inputs and labels before sorting the distances\n",
    "    inputs = pd.concat([inputs, labels], axis=1)\n",
    "    # sort based on distance\n",
    "    inputs = inputs.sort_values('distance', ascending=True)\n",
    "    # pick k neighbors\n",
    "    neighbors = inputs.head(k)\n",
    "\n",
    "    # get list from dataframe column\n",
    "    classes = neighbors['CLASS'].tolist()\n",
    "\n",
    "    # create counter of labels\n",
    "    majority_count = Counter(classes)\n",
    "    return majority_count.most_common(1).pop()[0]\n",
    "\n",
    "def knn(X_train, y_train, X_test, k):\n",
    "    \"\"\"\n",
    "    Calculate k-nn for given k.\n",
    "    \n",
    "    \"\"\"\n",
    "    predictions = np.zeros(X_test.shape[0])\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    for index, row in X_test.iterrows():\n",
    "        predictions[index] = predict_instance(X_train.copy(), y_train.copy(), row, k)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = KNN(3)\n",
    "predictions = knn(X_train, y_train, X_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7222222222222222"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_values = y_test.to_numpy()\n",
    "accuracy = np.mean(predictions == true_values)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  a.  %timeit magic command to observe execution time for core python functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 ms ± 11.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "# -n execute the function 10 times in a loop\n",
    "%timeit -n 10 knn(X_train, y_train, X_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Line profiling to see which functions/call has higher contribution on execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are profiling function knn, we supply the name using -f\n",
    "%lprun -f knn knn(X_train, y_train, X_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 0.312758 s\n",
    "File: <ipython-input-115-bd6cbd244598>\n",
    "Function: knn at line 18\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    18                                           def knn(X_train, y_train, X_test, k):\n",
    "    19                                               \"\"\"\n",
    "    20                                               Calculate k-nn for given k.\n",
    "    21                                               \n",
    "    22                                               \"\"\"\n",
    "    23         1         55.0     55.0      0.0      predictions = np.zeros(X_test.shape[0])\n",
    "    24         1        586.0    586.0      0.2      X_test.reset_index(drop=True, inplace=True)\n",
    "    25        19       3188.0    167.8      1.0      for index, row in X_test.iterrows():\n",
    "    26        18     308928.0  17162.7     98.8          predictions[index] = predict_instance(X_train.copy(), y_train.copy(), row, k)\n",
    "    27         1          1.0      1.0      0.0      return predictions\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "NOTE:\n",
    "1. Time is in microseconds at mentioned at the top of the cell.\n",
    "2. (Hits) shows number of times that particular line in code executed.\n",
    "3. (Time) total microseconds for executing that line. (total amount of time)\n",
    "4. (per Hit) = (Time)/(Hits),  average time for a single execution. \n",
    "5. (% Time) fraction of time spent on that line relative to total amount of time.\n",
    "\n",
    "We can see the line number 26 is expensive one. We will improve it using numpy below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Improving kNN with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_instance_numpy(inputs, labels, test_instance, k):\n",
    "    # calculate L2 norm between all training points and given test_point\n",
    "    inputs['distance'] = np.linalg.norm(inputs.values-test_instance.values, axis=1)\n",
    "\n",
    "    # concatenate inputs and labels before sorting the distances\n",
    "    inputs = pd.concat([inputs, labels], axis=1)\n",
    "    # sort based on distance\n",
    "    inputs = inputs.sort_values('distance', ascending=True)\n",
    "    \n",
    "    # pick k neighbors\n",
    "    neighbors = inputs.head(k)\n",
    "\n",
    "    # get list from dataframe column\n",
    "    classes = neighbors['CLASS'].tolist()\n",
    "\n",
    "    # create counter of labels\n",
    "    majority_count = Counter(classes)\n",
    "    return majority_count.most_common(1).pop()[0]\n",
    "\n",
    "def knn_numpy(X_train, y_train, X_test, k):\n",
    "    \"\"\"\n",
    "    Calculate k-nn for given k.\n",
    "    \n",
    "    \"\"\"\n",
    "    predictions = np.zeros(X_test.shape[0])\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    for index, row in X_test.iterrows():\n",
    "        predictions[index] = predict_instance_numpy(X_train.copy(), y_train.copy(), row, k)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7222222222222222"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn improved with distance calculation using np.linalg.norm\n",
    "predictions = knn_numpy(X_train, y_train, X_test, 3)\n",
    "true_values = y_test.to_numpy()\n",
    "accuracy = np.mean(predictions == true_values)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Observing execution time and line profiling after optimizing with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.6 ms ± 2.41 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "# -n execute the function 10 times in a loop\n",
    "%timeit -n 10 knn_numpy(X_train, y_train, X_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> The total execution has reduced from 135 ms to 41.2 ms </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are profiling function knn, we supply the name using -f\n",
    "%lprun -f knn_numpy knn_numpy(X_train, y_train, X_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 0.094862 s\n",
    "File: <ipython-input-121-a0da67624daf>\n",
    "Function: knn_numpy at line 22\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    22                                           def knn_numpy(X_train, y_train, X_test, k):\n",
    "    23                                               \"\"\"\n",
    "    24                                               Calculate k-nn for given k.\n",
    "    25                                               \n",
    "    26                                               \"\"\"\n",
    "    27         1         65.0     65.0      0.1      predictions = np.zeros(X_test.shape[0])\n",
    "    28         1        258.0    258.0      0.3      X_test.reset_index(drop=True, inplace=True)\n",
    "    29        19       3696.0    194.5      3.9      for index, row in X_test.iterrows():\n",
    "    30        18      90843.0   5046.8     95.8          predictions[index] = predict_instance_numpy(X_train.copy(), y_train.copy(), row, k)\n",
    "    31         1          0.0      0.0      0.0      return predictions\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> The per Hit time has reduced from 17162.7 µs to 5046.8 µs </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Improving kNN with numba\n",
    "\n",
    "\n",
    "Numba does it's best work when we do operations over numpy arrays. For the implemention below, I have converted pandas dataframe to numpy array and perform relevant operations.\n",
    "\n",
    "For more information about [numba](https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html#using-numba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import numba\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def euclidean_distance_numba(vector1, vector2):\n",
    "    '''calculate the euclidean distance,\n",
    "    '''\n",
    "    dist = np.linalg.norm(vector1-vector2)\n",
    "    return dist\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def predict_instance_numba(inputs, labels, test_instance, k):\n",
    "    distances = np.zeros((inputs.shape[0], 1))\n",
    "    # calculate distance between test point and training points\n",
    "    for i in np.arange(inputs.shape[0]):\n",
    "        distances[i] = euclidean_distance_numba(inputs[i], test_instance)\n",
    "    labels = labels.reshape((labels.shape[0],1))\n",
    "    \n",
    "    # add labels column\n",
    "    inputs = np.hstack((inputs, labels))\n",
    "    \n",
    "    # add distance column\n",
    "    inputs = np.hstack((inputs, distances))\n",
    "    \n",
    "    # sort based on distance column\n",
    "    inputs = inputs[inputs[:,3].argsort()]\n",
    "    # 2nd columns contains classes, select first k values\n",
    "    neighbor_classes = inputs[:, 2][:k]\n",
    "    counter = {}\n",
    "    for item in neighbor_classes:\n",
    "        if item in counter:\n",
    "            counter[item] = counter.get(item) + 1\n",
    "        else:\n",
    "            counter[item] = 1\n",
    "    counter_sorted = sorted(counter)\n",
    "    return counter_sorted[0]\n",
    "\n",
    "# @numba.jit(nopython=True)\n",
    "def knn_numba(X_train, y_train, X_test, k):\n",
    "    \"\"\"\n",
    "    Calculate k-nn for given k.\n",
    "    \n",
    "    \"\"\"\n",
    "    predictions = np.zeros(X_test.shape[0])\n",
    "    for i in np.arange(X_test.shape[0]):\n",
    "        predictions[i] = predict_instance_numba(X_train.copy(), y_train.copy(), X_test[i], k)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7222222222222222"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn improved with distance calculation using np.linalg.norm\n",
    "predictions = knn_numba(X_train.values, y_train.values, X_test.values, 3)\n",
    "true_values = y_test.to_numpy()\n",
    "accuracy = np.mean(predictions == true_values)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing execution time and line profiling after optimizing with numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.65 ms ± 362 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "# -n execute the function 10 times in a loop\n",
    "%timeit -n 10 knn_numba(X_train.values, y_train.values, X_test.values, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> The total execution has reduced from 41.2 ms to 1.65 ms </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are profiling function knn_numba, we supply the name using -f\n",
    "%lprun -f knn_numba knn_numba(X_train.values, y_train.values, X_test.values, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 0.002649 s\n",
    "File: <ipython-input-79-89228ad76421>\n",
    "Function: knn_numba at line 36\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    36                                           def knn_numba(X_train, y_train, X_test, k):\n",
    "    37                                               \"\"\"\n",
    "    38                                               Calculate k-nn for given k.\n",
    "    39                                               \n",
    "    40                                               \"\"\"\n",
    "    41         1         11.0     11.0      0.4      predictions = np.zeros(X_test.shape[0])\n",
    "    42        19         44.0      2.3      1.7      for i in np.arange(X_test.shape[0]):\n",
    "    43        18       2593.0    144.1     97.9          predictions[i] = predict_instance_numba(X_train.copy(), y_train.copy(), X_test[i], k)\n",
    "    44         1          1.0      1.0      0.0      return predictions\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> The per Hit time has reduced from 5046.8 µs 144.1 µs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nikola": {
   "category": "",
   "date": "2020-05-23 13:55:45 UTC+05:45",
   "description": "",
   "link": "",
   "slug": "optimizing-k-nearest-neighbors-knn-algorithm-in-python",
   "tags": "",
   "title": "Optimizing k-Nearest Neighbors (kNN) algorithm in Python",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
