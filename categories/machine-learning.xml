<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CODEBUG (Posts about machine-learning)</title><link>https://sijanb.com.np/</link><description></description><atom:link href="https://sijanb.com.np/categories/machine-learning.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2024 &lt;a href="mailto:sijanonly@gmail.com"&gt;Sijan Bhandari&lt;/a&gt; </copyright><lastBuildDate>Sat, 11 May 2024 08:58:59 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>What is gradient descent ?</title><link>https://sijanb.com.np/posts/what-is-gradient-descent/</link><dc:creator>Sijan Bhandari</dc:creator><description>&lt;p&gt;Gradient descent is a widely used optimization approach for training machine learning models and neural networks. Optimization is the process of minimizing or increasing an objective function.
Optimization entails calculating the gradient (partial derivatives) of the cost function for each parameter (weights and biases). To do this, the models are given training data iteratively.
And, the gradient points are determined. The gradient represents the steepest rise in the function. Gradient descent lowers cost function values by going in the opposite direction of the steepest decrease.&lt;/p&gt;</description><category>gradient-descent</category><category>machine-learning</category><category>machine-learning-glossary</category><guid>https://sijanb.com.np/posts/what-is-gradient-descent/</guid><pubDate>Sat, 11 May 2024 07:02:15 GMT</pubDate></item><item><title>What is Inductive Bias in Machine Learning ?</title><link>https://sijanb.com.np/posts/what-is-inductive-bias-in-machine-learning/</link><dc:creator>Sijan Bhandari</dc:creator><description>&lt;p&gt;An explicit or implicit assumption or prior information about the model that permits it to generalize
outside of the training set of data is known as inductive bias.&lt;/p&gt;
&lt;p&gt;Examples of inductive bias:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;When it comes to decision trees, shorter trees work better than longer ones.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable (y) in linear regression is thought to vary linearly in predictors (X).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In general, the belief that the most simplest hypothesis is more accurate than the more complicated one (Occam's razor) .&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;</description><category>inductive-bias</category><category>machine-learning</category><category>machine-learning-glossary</category><guid>https://sijanb.com.np/posts/what-is-inductive-bias-in-machine-learning/</guid><pubDate>Thu, 09 May 2024 19:21:31 GMT</pubDate></item><item><title>What are model training steps in machine learning ?</title><link>https://sijanb.com.np/posts/machine-learning-glossary-what-are-model-training-steps/</link><dc:creator>Sijan Bhandari</dc:creator><description>&lt;p&gt;There may exist many possible models to solve a given problem at hand. Based on your modeling decision there are usually two different ways to complete the machine learning lifecycle.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;1st scenario. Training a single model with a training dataset and final evaluation with the test set.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2nd scenario. Training multiple models with training/validation dataset and final evaluation with the test set.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In case of (1st scenario), you will follow the following approach:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Divide the data into training and test sets. (Usually 70/30 splits)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select your preferable model.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Train it with a training dataset.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Assess the trained model in the test set. (no need to perform validation in your trained model)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In case of (2nd scenario), you will follow the following approach:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Divide the data into training, validation, and test sets. (Usually 50/25/25 splits)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the initial model/architecture.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Train the model with a training dataset.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Evaluate the model using the validation dataset.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Repeat steps (b) through (d) for different models or training parameters.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the best model based on evaluation and train the best model with combined (training + validation) datasets.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Assess the trained model in the test set.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>machine-learning</category><category>machine-learning-glossary</category><category>model-evaluation</category><category>training-validation-test</category><guid>https://sijanb.com.np/posts/machine-learning-glossary-what-are-model-training-steps/</guid><pubDate>Mon, 06 May 2024 18:51:31 GMT</pubDate></item><item><title>what is model training in machine learning ?</title><link>https://sijanb.com.np/posts/machine-learning-glossary-what-is-model-training-in-machine-learning/</link><dc:creator>Sijan Bhandari</dc:creator><description>&lt;p&gt;The Machine Learning model is represented by the model parameters. Those parameters are the learnable parameters. Learning happens when these parameters are updated with suitable values and the model is able to solve the given tasks.
Training is the process of feeding a training dataset to your model. The training process uses an objective function (example MSE) to get the feedback in each iteration. Since we are trying to improve the accuracy of the model on a given
input, and lower the error between model prediction and actual output, we also called training process as a model optimization process.&lt;/p&gt;</description><category>machine-learning</category><category>machine-learning-glossary</category><guid>https://sijanb.com.np/posts/machine-learning-glossary-what-is-model-training-in-machine-learning/</guid><pubDate>Mon, 06 May 2024 17:59:07 GMT</pubDate></item><item><title>What is machine learning ?</title><link>https://sijanb.com.np/posts/machine-learning-glossary-what-is-machine-learning/</link><dc:creator>Sijan Bhandari</dc:creator><description>&lt;p&gt;Understanding and extracting hidden patterns or features from the data is the learning process in machine learning. Instead of using explicit
logic supplied by people, machine learning has the capacity to learn from experiences.
Conventional systems are created with the use of well defined human-set rules. In order for machine learning algorithms
to understand complicated patterns from inputs (x), they use outputs (y) as a feedback signal. Thus, an intelligent program is the ML system's
final product.&lt;/p&gt;
&lt;p&gt;We often use a logical method to solve any issue. We make an effort to break the task up into several smaller tasks and solve each smaller task
using a distinct rationale. When dealing with extremely complicated jobs, like stock price prediction, the patterns are always changing,
which has an impact on the results.
That implies that, in order to answer this problem logically, we must adjust our handwritten logic for each new change in the outputs.
Machine Learning (ML), on the other hand, creates the model using a vast amount of data. The data gives the model all of its historical experience,
which helps it better understand the pattern. We just retrain the model with fresh instances whenever the data changes.&lt;/p&gt;</description><category>machine-learning</category><category>machine-learning-glossary</category><guid>https://sijanb.com.np/posts/machine-learning-glossary-what-is-machine-learning/</guid><pubDate>Sun, 05 May 2024 10:28:45 GMT</pubDate></item><item><title>Out-of-sample accuracy estimation using Cross validation in python and scikit-learn</title><link>https://sijanb.com.np/posts/out-of-sample-accuracy-estimation-using-cross-validation-in-python-and-scikit-learn/</link><dc:creator>Sijan Bhandari</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this post, we will be continuing from our previous post:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="http://sijanb.com.np/posts/k-nearest-neighbors-algorithm-using-python-and-scikit-learn/"&gt;K-Nearest Neighbors Algorithm using Python and Scikit-Learn?&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Before starting with the implementation, let's discuss few important points in cross validation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Using Cross validation (CV), we splits our dataset into k folds (k generally setup by developer)&lt;/li&gt;
&lt;li&gt;Once you created k folds, you use each of the folds as test set during run and all remaining folds as train set.&lt;/li&gt;
&lt;li&gt;With cross validation, one can assess the average model performance (this post) or also for the hyperparameters selection (for example : selecting optimal neighbors size(k) in kNN) or selecting good feature
combinations from given data features.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;InÂ [1]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline

&lt;span class="c1"&gt;# making results reproducible&lt;/span&gt;
&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;InÂ [2]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s1"&gt;'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;','&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'CLASS'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ALCOHOL_LEVEL'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'MALIC_ACID'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ASH'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ALCALINITY'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;'MAGNESIUM'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'PHENOLS'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
              &lt;span class="s1"&gt;'FLAVANOIDS'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'NON_FLAVANOID_PHENOL'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'PROANTHOCYANINS'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'COLOR_INTENSITY'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
              &lt;span class="s1"&gt;'HUE'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'OD280/OD315_DILUTED'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;'PROLINE'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# Let us use only two features : 'ALCOHOL_LEVEL', 'MALIC_ACID' for this problem&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s1"&gt;'CLASS'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ALCOHOL_LEVEL'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'MALIC_ACID'&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="prompt output_prompt"&gt;Out[2]:&lt;/div&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;CLASS&lt;/th&gt;
&lt;th&gt;ALCOHOL_LEVEL&lt;/th&gt;
&lt;th&gt;MALIC_ACID&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;14.23&lt;/td&gt;
&lt;td&gt;1.71&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;13.20&lt;/td&gt;
&lt;td&gt;1.78&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;13.16&lt;/td&gt;
&lt;td&gt;2.36&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;14.37&lt;/td&gt;
&lt;td&gt;1.95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;13.24&lt;/td&gt;
&lt;td&gt;2.59&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="1.-Cross--validation-using-Python-from-Scratch"&gt;1. Cross  validation using Python from Scratch&lt;a class="anchor-link" href="https://sijanb.com.np/posts/out-of-sample-accuracy-estimation-using-cross-validation-in-python-and-scikit-learn/#1.-Cross--validation-using-Python-from-Scratch"&gt;Â¶&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://sijanb.com.np/posts/out-of-sample-accuracy-estimation-using-cross-validation-in-python-and-scikit-learn/"&gt;Read moreâ¦&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>cross-validation</category><category>kNN</category><category>machine-learning</category><guid>https://sijanb.com.np/posts/out-of-sample-accuracy-estimation-using-cross-validation-in-python-and-scikit-learn/</guid><pubDate>Sat, 09 May 2020 08:49:17 GMT</pubDate></item><item><title>K-Nearest Neighbors Algorithm using Python and Scikit-Learn</title><link>https://sijanb.com.np/posts/k-nearest-neighbors-algorithm-using-python-and-scikit-learn/</link><dc:creator>Sijan Bhandari</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;K nearest Neighbors (kNN) works based on calculating distance between given test data point and all the training samples. We, then, collect first K closest points from training set and the majority vote gives you the predicted class for a given test data point.&lt;/p&gt;
&lt;p&gt;For more intuitive explanation, please follow previous post :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://sijanb.com.np/posts/how-k-nearest-neighbors-works/"&gt;How kNN works ?&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;InÂ [1]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline

&lt;span class="c1"&gt;# making results reproducible&lt;/span&gt;
&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;InÂ [2]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s1"&gt;'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;','&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'CLASS'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ALCOHOL_LEVEL'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'MALIC_ACID'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ASH'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ALCALINITY'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;'MAGNESIUM'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'PHENOLS'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
              &lt;span class="s1"&gt;'FLAVANOIDS'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'NON_FLAVANOID_PHENOL'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'PROANTHOCYANINS'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'COLOR_INTENSITY'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
              &lt;span class="s1"&gt;'HUE'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'OD280/OD315_DILUTED'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;'PROLINE'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# Let us use only two features : 'ALCOHOL_LEVEL', 'MALIC_ACID' for this problem&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s1"&gt;'CLASS'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ALCOHOL_LEVEL'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'MALIC_ACID'&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="prompt output_prompt"&gt;Out[2]:&lt;/div&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;CLASS&lt;/th&gt;
&lt;th&gt;ALCOHOL_LEVEL&lt;/th&gt;
&lt;th&gt;MALIC_ACID&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;14.23&lt;/td&gt;
&lt;td&gt;1.71&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;13.20&lt;/td&gt;
&lt;td&gt;1.78&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;13.16&lt;/td&gt;
&lt;td&gt;2.36&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;14.37&lt;/td&gt;
&lt;td&gt;1.95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;13.24&lt;/td&gt;
&lt;td&gt;2.59&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;InÂ [3]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# class distribution looks okay; not so imbalanced.&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'CLASS'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"bar"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_png output_subarea"&gt;
&lt;img alt="No description has been provided for this image" src="data:image/png;base64,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"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://sijanb.com.np/posts/k-nearest-neighbors-algorithm-using-python-and-scikit-learn/"&gt;Read moreâ¦&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>kNN</category><category>machine-learning</category><guid>https://sijanb.com.np/posts/k-nearest-neighbors-algorithm-using-python-and-scikit-learn/</guid><pubDate>Sat, 02 May 2020 09:38:27 GMT</pubDate></item><item><title>How k-Nearest Neighbors works?</title><link>https://sijanb.com.np/posts/how-k-nearest-neighbors-works/</link><dc:creator>Sijan Bhandari</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;K-Nearest Neighbors (k-NN) is one of the classification algorithms in Machine learing. Since, K-NN simply memories or stores the rules in memory, we can also say that it does not learn the mapping function(f) between inputs and labels.&lt;/p&gt;
&lt;p&gt;The kNN algorithm can be summarized in following four steps:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. Compute distance between the test point and each of the training points
2. Sort the distances in descending order
3. Pick 'k' nearest neighbors from the sorted items
4. Apply majority vote of labels for classification or averaging of label values for regression problem.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Before going to implementation, let us build some standard notation so that it is easier to follow the code in the implementation section (next post):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;          X_training = given training data
          Y = labels for your given training data
          X_test = new data (For which we need to predict the labels)
          &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The whole algorithm can be divided into three major steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Finding most nearest neighbors (similar data instances) from your training data for a given test data (X_test)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Let's say we have total 20 training data, and you find out 4 training instances as nearest neighbors for
one of your test data&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Once you get the nearest neighbors from your training data, collect all the labels of your selected training
data&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;In our case, we have 4 training instances as nearest neighbors. So, we will collect labels for all
these 4 training data. &lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finally, predict the label of your test data (X_test) based on majority count.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;In our case, suppose 3 out of 4 training instances have the same label. Then, the majority count
will assign the label to new data point&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The &lt;code&gt;K&lt;/code&gt; defines the number of neighbors that the algorithm will collect for making the prediction of your new data.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://sijanb.com.np/posts/how-k-nearest-neighbors-works/"&gt;Read moreâ¦&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>kNN</category><category>machine-learning</category><guid>https://sijanb.com.np/posts/how-k-nearest-neighbors-works/</guid><pubDate>Fri, 26 Apr 2019 18:31:44 GMT</pubDate></item></channel></rss>